{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T12:29:35.155529Z",
     "start_time": "2025-06-30T12:29:35.137670Z"
    }
   },
   "source": [
    "from langchain import hub\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "\n",
    "from db.db import get_session\n",
    "from db.models import Grade\n",
    "from dto.response.matrix_chats import MessageDict\n",
    "import os\n",
    "from typing import TypedDict, Annotated, Literal, List, Any, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage, SystemMessage\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.graph import StateGraph, START, END, add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from service.service import BaseService\n",
    "from utils.common import convert_msg_dict_to_langgraph_format\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "LITE_LLM_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# LITE_LLM_URL = os.getenv(\"OPENAI_BASE_URL\")\n",
    "# LITE_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "\n",
    "# model = ChatOpenAI(\n",
    "#     model=LITE_MODEL,\n",
    "#     api_key=LITE_LLM_API_KEY,\n",
    "#     base_url=LITE_LLM_URL,\n",
    "#     streaming=True,\n",
    "#     verbose=True,\n",
    "# )\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=LITE_LLM_API_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "class AnswerClassification(BaseModel):\n",
    "    categorization: str = Field(description=\"classification\")\n",
    "    note: str = Field(description=\"short additional notes from your observation\")\n",
    "\n",
    "\n",
    "class GuidanceState(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "    classification: str\n",
    "    irregularity_amount: Optional[int]\n",
    "\n",
    "\n",
    "async def prepare_discussion(messages: list[BaseMessage]) -> str:\n",
    "    discussion = \"\"\n",
    "    print(f\"Preparing discussion for {messages}\")\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            discussion += f\"Question: {msg.content}\\n\"\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            discussion += f\"Answer: {msg.content}\\n\"\n",
    "    print(f\"Discussion:\\n{discussion}\")\n",
    "    return discussion\n",
    "\n",
    "\n",
    "async def classify_answer(state: GuidanceState) -> GuidanceState:\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "You are classifying discussion (question noted with \"Question/Statement:\" and answer noted with \"Answer:\" within pairs) with user to a question to one of the following categories:\n",
    "direct: answer makes sense and unquestionably answers the question that was asked, without any ambiguity, confusion, evasion, make belief or contradiction\n",
    "need_help: When user needs additional help with the question or is asking a question related to the question we asked\n",
    "evasion: When user is evading to answer clearly a question, or when intentionally creating confusion\n",
    "confusion: When user seems to be confused on the question\n",
    "unknown: When other categories do not apply\n",
    "\n",
    "Please prioritize the latest answers than the question and answers from beginning of the discussion!\n",
    "Answer with the categorization without additional explanation!\n",
    "Please answer directly to the user!\n",
    "Original question is the most important question explaining the purpose and intent of the conversation!\n",
    "\n",
    "Discussion:\n",
    "{discussion}\n",
    "        \"\"\",\n",
    "        )\n",
    "    )\n",
    "    structured_model = model.with_structured_output(AnswerClassification)\n",
    "    full_discussion = await prepare_discussion(state[\"messages\"])\n",
    "    prompt = prompt_template.format(discussion=full_discussion)\n",
    "\n",
    "    answer = await structured_model.ainvoke(prompt)\n",
    "    print(\"CLASSIFY ANSWER ANSWER\", answer.categorization)\n",
    "    msgs = [AIMessage(answer.categorization)]\n",
    "    if answer.categorization == \"direct\":\n",
    "        msgs = []\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"classification\": answer.categorization,\n",
    "        \"question\": None,\n",
    "        \"answer\": answer.categorization,\n",
    "        \"irregularity_amount\": state[\"irregularity_amount\"],\n",
    "    }\n",
    "\n",
    "\n",
    "async def need_help(state: GuidanceState) -> GuidanceState:\n",
    "    print(\"NEED HELP\")\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Provide additional help and explanation to the user explaining the original intent based on the entire\n",
    "            Discussion.\n",
    "            Discussion contains Question Answer pairs noted with question \"Question/Statement:\" and \"Answer:\"\n",
    "            Give the user options and possibilities to help him get to the final answer.\n",
    "            Original question is the most important question explaining the purpose and intent of the conversation!\n",
    "            Please answer directly to the user!\n",
    "            Here is the Discussion:\n",
    "            {discussion}\n",
    "            \"\"\",\n",
    "        )\n",
    "    )\n",
    "    full_discussion = await prepare_discussion(state[\"messages\"])\n",
    "    prompt = prompt_template.format(discussion=full_discussion)\n",
    "\n",
    "    answer = await model.ainvoke(prompt)\n",
    "    print(\"NEED HELP ANSWER\", answer.content)\n",
    "    return {\n",
    "        \"messages\": [AIMessage(answer.content)],\n",
    "        \"classification\": state[\"classification\"],\n",
    "        \"question\": state[\"question\"],\n",
    "        \"answer\": state[\"answer\"],\n",
    "        \"irregularity_amount\": state[\"irregularity_amount\"],\n",
    "    }\n",
    "\n",
    "\n",
    "async def evasion(state: GuidanceState) -> GuidanceState:\n",
    "    print(\"EVASION\")\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "        The user is evading the question, providing irrelevant or unrelated answers to the questions based on the discussion.\n",
    "        Please provide a user with explanation that if continued this will be escalated to managers.\n",
    "        Original question is the most important question explaining the purpose and intent of the conversation!\n",
    "        Please answer directly to the user!\n",
    "\n",
    "        Here is the discussion:\n",
    "        {discussion}\n",
    "        \"\"\",\n",
    "        )\n",
    "    )\n",
    "    full_discussion = await prepare_discussion(state[\"messages\"])\n",
    "\n",
    "    prompt = prompt_template.format(discussion=full_discussion)\n",
    "    answer = await model.ainvoke(prompt)\n",
    "    print(\"EVASION ANSWER\", answer.content)\n",
    "    return {\n",
    "        \"messages\": [AIMessage(answer.content)],\n",
    "        \"classification\": state[\"classification\"],\n",
    "        \"question\": state[\"question\"],\n",
    "        \"answer\": state[\"answer\"],\n",
    "        \"irregularity_amount\": state[\"irregularity_amount\"] + 1,\n",
    "    }\n",
    "\n",
    "\n",
    "async def confusion(state: GuidanceState) -> GuidanceState:\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "        The user seems to be confused on the question based on the entire discussion.\n",
    "        Reiterate the question with additional details explaining better.\n",
    "        Original question is the most important question explaining the purpose and intent of the conversation!\n",
    "        Please answer directly to the user!\n",
    "        Here is the discussion:\n",
    "        {discussion}\n",
    "        \"\"\",\n",
    "        )\n",
    "    )\n",
    "    full_discussion = await prepare_discussion(state[\"messages\"])\n",
    "    prompt = prompt_template.format(discussion=full_discussion)\n",
    "    answer = await model.ainvoke(prompt)\n",
    "    print(\"CONFUSION ANSWER\", answer.content)\n",
    "    return {\n",
    "        \"messages\": [AIMessage(answer.content)],\n",
    "        \"classification\": state[\"classification\"],\n",
    "        \"question\": state[\"question\"],\n",
    "        \"answer\": state[\"answer\"],\n",
    "        \"irregularity_amount\": state[\"irregularity_amount\"] + 1,\n",
    "    }\n",
    "\n",
    "\n",
    "async def route_to_individual_helper(\n",
    "    state: GuidanceState,\n",
    ") -> Literal[\"need_help\", \"evasion\", \"direct\", \"confusion\"]:\n",
    "    if state[\"classification\"] == \"need_help\":\n",
    "        return \"need_help\"\n",
    "    elif state[\"classification\"] == \"evasion\":\n",
    "        return \"evasion\"\n",
    "    elif state[\"classification\"] == \"direct\":\n",
    "        return \"direct\"\n",
    "    else:\n",
    "        return \"confusion\"\n",
    "\n",
    "\n",
    "async def finish(state: GuidanceState) -> GuidanceState:\n",
    "    return state\n",
    "\n",
    "\n",
    "async def direct(state: GuidanceState) -> GuidanceState:\n",
    "    return state\n",
    "\n",
    "\n",
    "async def build_graph() -> CompiledGraph:\n",
    "    classify_answers = StateGraph(GuidanceState)\n",
    "    classify_answers.add_node(\"classify_answer\", classify_answer)\n",
    "    classify_answers.add_node(\"evasion\", evasion)\n",
    "    classify_answers.add_node(\"confusion\", confusion)\n",
    "    classify_answers.add_node(\"need_help\", need_help)\n",
    "    classify_answers.add_node(\"finish\", finish)\n",
    "    classify_answers.add_node(\"direct\", direct)\n",
    "    classify_answers.add_edge(START, \"classify_answer\")\n",
    "    classify_answers.add_conditional_edges(\n",
    "        \"classify_answer\", route_to_individual_helper\n",
    "    )\n",
    "    classify_answers.add_edge(\"need_help\", \"finish\")\n",
    "    classify_answers.add_edge(\"evasion\", \"finish\")\n",
    "    classify_answers.add_edge(\"confusion\", \"finish\")\n",
    "    classify_answers.add_edge(\"direct\", END)\n",
    "    classify_answers.add_edge(\"finish\", END)\n",
    "\n",
    "    return classify_answers.compile()\n",
    "\n",
    "\n",
    "async def run_answer_classifier(messages: list[MessageDict]) -> dict:\n",
    "    graph = await build_graph()\n",
    "    messages_to_send = convert_msg_dict_to_langgraph_format(messages)\n",
    "    result = await graph.ainvoke(\n",
    "        {\n",
    "            \"messages\": messages_to_send,\n",
    "            \"classification\": \"\",\n",
    "        }\n",
    "    )\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "class GuidanceHelperStdOutput(BaseModel):\n",
    "    has_user_answered: bool = Field(\n",
    "        description=\"Whether the user has correctly answered the topic at hand\"\n",
    "    )\n",
    "    expertise_level: str = Field(\n",
    "        description=\"The expertise user has self evaluated himself with\"\n",
    "    )\n",
    "    expertise_id: int = Field(description=\"The expertise or grade ID\")\n",
    "    should_admin_be_involved: bool = Field(\n",
    "        description=\"Whether the admin should be involved if user is evading the topic or fooling around\"\n",
    "    )\n",
    "    message: str = Field(description=\"Message to send to the user\")\n",
    "\n",
    "\n",
    "async def get_grades_or_expertise() -> List[Grade]:\n",
    "    \"\"\"\n",
    "    Useful tool to retrieve current grades or expertise level grading system\n",
    "    :return: List of json representing those grades and all their fields\n",
    "    \"\"\"\n",
    "    async for session in get_session():\n",
    "        service: BaseService[Grade, int, Any, Any] = BaseService(Grade, session)\n",
    "        all_db_grades = await service.list_all()\n",
    "        all_grades_json: List[str] = []\n",
    "        for grade in all_db_grades:\n",
    "            json_grade = grade.model_dump_json()\n",
    "            all_grades_json.append(json_grade)\n",
    "        return all_grades_json\n",
    "\n",
    "\n",
    "async def provide_guidance(msgs: List[str]) -> GuidanceHelperStdOutput:\n",
    "    tools = [\n",
    "        StructuredTool.from_function(\n",
    "            function=get_grades_or_expertise,\n",
    "            coroutine=get_grades_or_expertise,\n",
    "        )\n",
    "    ]\n",
    "    intermediate_steps = []\n",
    "\n",
    "    system_msg = \"\"\"\n",
    "    You are helping the user to properly grade their expertise in the mentioned field.\n",
    "    Everything you help him with should be done by utilizing the tools or around the topic\n",
    "    of helping him populate his expertise level on the topic.\n",
    "    Do not discuss anything except from the provided context.\n",
    "    You are guiding the user to evaluate himself on provided topic.\n",
    "    Do not discuss anything (any other topic) except from the ones provided in topic!\n",
    "    Do not chat about other topics with the user, guide him how to populate his expertise with the grades provided\n",
    "    Warn the user if answering with unrelated topics or evading to answer the question will be escalated by involving managers!\n",
    "    Topic: {context}\n",
    "    If the user is evading to answer the question and is not asking any questions related to the topic for 4 or 5 messages\n",
    "    please involve admin\n",
    "    When the user answers with proper categorization of skills return only that categorization!\n",
    "    \"\"\"\n",
    "    agent = create_react_agent(\n",
    "        model=model, tools=tools, response_format=GuidanceHelperStdOutput\n",
    "    )\n",
    "    async for chunk in agent.astream(\n",
    "        {\n",
    "            \"messages\": [SystemMessage(system_msg)] + msgs,\n",
    "            \"context\": msgs[0],\n",
    "            \"intermediate_steps\": intermediate_steps,\n",
    "        }\n",
    "    ):\n",
    "        print(\"CHUNK GUIDANCE\", chunk)\n",
    "        yield chunk"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T12:29:37.125789Z",
     "start_time": "2025-06-30T12:29:35.742034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dto.response.grades import GradeResponseBase\n",
    "from typing import List\n",
    "from utils.common import convert_msg_dict_to_langgraph_format\n",
    "import asyncio\n",
    "\n",
    "grades: List[GradeResponseBase] = [\n",
    "    GradeResponseBase(\n",
    "        id=1,\n",
    "        label=\"Not Informed\",\n",
    "        value=1\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=2,\n",
    "        label=\"Informed Basics\",\n",
    "        value=2\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=3,\n",
    "        label=\"Informed in Details\",\n",
    "        value=3\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=4,\n",
    "        label=\"Practice and Lab Examples\",\n",
    "        value=4\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=5,\n",
    "        label=\"Production Maintenance\",\n",
    "        value=5\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=6,\n",
    "        label=\"Production from Scratch\",\n",
    "        value=6\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=7,\n",
    "        label=\"Educator/Expert\",\n",
    "        value=7\n",
    "    ),\n",
    "]\n",
    "\n",
    "msgs: List[MessageDict] = [\n",
    "    MessageDict(\n",
    "        msg_type=\"ai\",\n",
    "        message=\"\"\"\n",
    "        Expertise in Cryptography\n",
    "        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\n",
    "\n",
    "        We offer various expertise grades to help you identify where you stand or where you want to grow:\n",
    "\n",
    "        Not Informed - Basic understanding of the subject.\n",
    "        Informed Basics - Familiarity with fundamental concepts.\n",
    "        Informed in Details - Comprehensive knowledge of the topic.\n",
    "        Practice and Lab Examples - Practical experience and demonstration.\n",
    "        Production Maintenance - Hands-on experience in maintaining production systems.\n",
    "        Production from Scratch - Ability to build production systems from the ground up.\n",
    "        Educator/Expert - Mastery of the subject, capable of teaching others.\n",
    "        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessageDict(\n",
    "        msg_type=\"human\",\n",
    "        message=\"\"\"\n",
    "        bla bla bla\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessageDict(\n",
    "        msg_type=\"ai\",\n",
    "        message=\"\"\"\n",
    "        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\n",
    "\n",
    "If this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessageDict(\n",
    "        msg_type=\"human\",\n",
    "        message=\"\"\"\n",
    "        Working great\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessageDict(\n",
    "        msg_type=\"ai\",\n",
    "        message=\"\"\"\n",
    "        User,\n",
    "\n",
    "        I noticed that the answers you've been providing are not directly addressing the questions asked and seem to be off-topic or unrelated. It's important for us to maintain clear and relevant communication to ensure that we can assist you effectively.\n",
    "\n",
    "        If this pattern continues, we may need to escalate the issue to our managers for further review. Please let us know if there's anything we can do to help or clarify things for you.\n",
    "\n",
    "        Thank you for your understanding and cooperation.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessageDict(\n",
    "        msg_type=\"human\",\n",
    "        message=\"\"\"\n",
    "        Practice and Lab Examples\n",
    "        \"\"\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "answer_classifier_response = await run_answer_classifier(msgs)\n",
    "print(\"FULL RESPONSE\", answer_classifier_response)"
   ],
   "id": "ebd88435fae7e7e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing discussion for [AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='e84b48aa-b763-4991-8a12-16b603b652dd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='e56307ad-ecc0-4552-80b5-19d93e35b4a3'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='752f2c22-0bf5-4835-94bc-3d18e9756d83'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='bccf1d2e-4800-4073-a064-d0b9859b0cf2'), AIMessage(content=\"\\n        User,\\n\\n        I noticed that the answers you've been providing are not directly addressing the questions asked and seem to be off-topic or unrelated. It's important for us to maintain clear and relevant communication to ensure that we can assist you effectively.\\n\\n        If this pattern continues, we may need to escalate the issue to our managers for further review. Please let us know if there's anything we can do to help or clarify things for you.\\n\\n        Thank you for your understanding and cooperation.\\n        \", additional_kwargs={}, response_metadata={}, id='528703a5-a87e-4aac-96ea-a4c1225b8e2a'), HumanMessage(content='\\n        Practice and Lab Examples\\n        ', additional_kwargs={}, response_metadata={}, id='cb653daf-6035-4bca-b3ee-017d75b7c5c3')]\n",
      "Discussion:\n",
      "Question: \n",
      "        Expertise in Cryptography\n",
      "        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\n",
      "\n",
      "        We offer various expertise grades to help you identify where you stand or where you want to grow:\n",
      "\n",
      "        Not Informed - Basic understanding of the subject.\n",
      "        Informed Basics - Familiarity with fundamental concepts.\n",
      "        Informed in Details - Comprehensive knowledge of the topic.\n",
      "        Practice and Lab Examples - Practical experience and demonstration.\n",
      "        Production Maintenance - Hands-on experience in maintaining production systems.\n",
      "        Production from Scratch - Ability to build production systems from the ground up.\n",
      "        Educator/Expert - Mastery of the subject, capable of teaching others.\n",
      "        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\n",
      "        \n",
      "Answer: \n",
      "        bla bla bla\n",
      "        \n",
      "Question: \n",
      "        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\n",
      "\n",
      "If this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\n",
      "        \n",
      "Answer: \n",
      "        Working great\n",
      "        \n",
      "Question: \n",
      "        User,\n",
      "\n",
      "        I noticed that the answers you've been providing are not directly addressing the questions asked and seem to be off-topic or unrelated. It's important for us to maintain clear and relevant communication to ensure that we can assist you effectively.\n",
      "\n",
      "        If this pattern continues, we may need to escalate the issue to our managers for further review. Please let us know if there's anything we can do to help or clarify things for you.\n",
      "\n",
      "        Thank you for your understanding and cooperation.\n",
      "        \n",
      "Answer: \n",
      "        Practice and Lab Examples\n",
      "        \n",
      "\n",
      "CLASSIFY ANSWER ANSWER direct\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'irregularity_amount'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 103\u001B[39m\n\u001B[32m      6\u001B[39m grades: List[GradeResponseBase] = [\n\u001B[32m      7\u001B[39m     GradeResponseBase(\n\u001B[32m      8\u001B[39m         \u001B[38;5;28mid\u001B[39m=\u001B[32m1\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     41\u001B[39m     ),\n\u001B[32m     42\u001B[39m ]\n\u001B[32m     44\u001B[39m msgs: List[MessageDict] = [\n\u001B[32m     45\u001B[39m     MessageDict(\n\u001B[32m     46\u001B[39m         msg_type=\u001B[33m\"\u001B[39m\u001B[33mai\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    100\u001B[39m     ),\n\u001B[32m    101\u001B[39m ]\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m answer_classifier_response = \u001B[38;5;28;01mawait\u001B[39;00m run_answer_classifier(msgs)\n\u001B[32m    104\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFULL RESPONSE\u001B[39m\u001B[33m\"\u001B[39m, answer_classifier_response)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 242\u001B[39m, in \u001B[36mrun_answer_classifier\u001B[39m\u001B[34m(messages)\u001B[39m\n\u001B[32m    240\u001B[39m graph = \u001B[38;5;28;01mawait\u001B[39;00m build_graph()\n\u001B[32m    241\u001B[39m messages_to_send = convert_msg_dict_to_langgraph_format(messages)\n\u001B[32m--> \u001B[39m\u001B[32m242\u001B[39m result = \u001B[38;5;28;01mawait\u001B[39;00m graph.ainvoke(\n\u001B[32m    243\u001B[39m     {\n\u001B[32m    244\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: messages_to_send,\n\u001B[32m    245\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    246\u001B[39m     }\n\u001B[32m    247\u001B[39m )\n\u001B[32m    248\u001B[39m \u001B[38;5;28mprint\u001B[39m(result)\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2788\u001B[39m, in \u001B[36mPregel.ainvoke\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001B[39m\n\u001B[32m   2785\u001B[39m chunks: \u001B[38;5;28mlist\u001B[39m[Union[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any], Any]] = []\n\u001B[32m   2786\u001B[39m interrupts: \u001B[38;5;28mlist\u001B[39m[Interrupt] = []\n\u001B[32m-> \u001B[39m\u001B[32m2788\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.astream(\n\u001B[32m   2789\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   2790\u001B[39m     config,\n\u001B[32m   2791\u001B[39m     stream_mode=stream_mode,\n\u001B[32m   2792\u001B[39m     output_keys=output_keys,\n\u001B[32m   2793\u001B[39m     interrupt_before=interrupt_before,\n\u001B[32m   2794\u001B[39m     interrupt_after=interrupt_after,\n\u001B[32m   2795\u001B[39m     checkpoint_during=checkpoint_during,\n\u001B[32m   2796\u001B[39m     debug=debug,\n\u001B[32m   2797\u001B[39m     **kwargs,\n\u001B[32m   2798\u001B[39m ):\n\u001B[32m   2799\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode == \u001B[33m\"\u001B[39m\u001B[33mvalues\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   2800\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2801\u001B[39m             \u001B[38;5;28misinstance\u001B[39m(chunk, \u001B[38;5;28mdict\u001B[39m)\n\u001B[32m   2802\u001B[39m             \u001B[38;5;129;01mand\u001B[39;00m (ints := chunk.get(INTERRUPT)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   2803\u001B[39m         ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2655\u001B[39m, in \u001B[36mPregel.astream\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[39m\n\u001B[32m   2653\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m task \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m loop.amatch_cached_writes():\n\u001B[32m   2654\u001B[39m     loop.output_writes(task.id, task.writes, cached=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m2655\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner.atick(\n\u001B[32m   2656\u001B[39m     [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m loop.tasks.values() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t.writes],\n\u001B[32m   2657\u001B[39m     timeout=\u001B[38;5;28mself\u001B[39m.step_timeout,\n\u001B[32m   2658\u001B[39m     get_waiter=get_waiter,\n\u001B[32m   2659\u001B[39m     schedule_task=loop.aaccept_push,\n\u001B[32m   2660\u001B[39m ):\n\u001B[32m   2661\u001B[39m     \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[32m   2662\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m output():\n\u001B[32m   2663\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m o\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 105\u001B[39m, in \u001B[36mclassify_answer\u001B[39m\u001B[34m(state)\u001B[39m\n\u001B[32m     98\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m answer.categorization == \u001B[33m\"\u001B[39m\u001B[33mdirect\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     99\u001B[39m     msgs = []\n\u001B[32m    100\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m    101\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: msgs,\n\u001B[32m    102\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m\"\u001B[39m: answer.categorization,\n\u001B[32m    103\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mquestion\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    104\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33manswer\u001B[39m\u001B[33m\"\u001B[39m: answer.categorization,\n\u001B[32m--> \u001B[39m\u001B[32m105\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mirregularity_amount\u001B[39m\u001B[33m\"\u001B[39m: \u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mirregularity_amount\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m,\n\u001B[32m    106\u001B[39m }\n",
      "\u001B[31mKeyError\u001B[39m: 'irregularity_amount'",
      "During task with name 'classify_answer' and id '9f1a171e-9d7c-1a45-24f1-821e69fcb57d'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T12:29:50.416236Z",
     "start_time": "2025-06-30T12:29:50.413914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "formatted_msgs = convert_msg_dict_to_langgraph_format(msgs)\n",
    "discussion = await prepare_discussion({\"messages\": formatted_msgs})\n",
    "print(discussion)"
   ],
   "id": "45b5582e3602ebcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing discussion for {'messages': [AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}), AIMessage(content=\"\\n        User,\\n\\n        I noticed that the answers you've been providing are not directly addressing the questions asked and seem to be off-topic or unrelated. It's important for us to maintain clear and relevant communication to ensure that we can assist you effectively.\\n\\n        If this pattern continues, we may need to escalate the issue to our managers for further review. Please let us know if there's anything we can do to help or clarify things for you.\\n\\n        Thank you for your understanding and cooperation.\\n        \", additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n        Practice and Lab Examples\\n        ', additional_kwargs={}, response_metadata={})]}\n",
      "Discussion:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T12:29:53.682526Z",
     "start_time": "2025-06-30T12:29:51.781762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EvalLine(BaseModel):\n",
    "    input: str\n",
    "    output: str\n",
    "\n",
    "\n",
    "with open(\"eval.jsonl\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[0:10]:\n",
    "        eval_line = EvalLine.model_validate_json(line)\n",
    "        ai_msg = MessageDict(msg_type=\"ai\", message=eval_line.input)\n",
    "        human_msg = MessageDict(msg_type=\"human\", message=eval_line.output)\n",
    "        # print(eval_line)\n",
    "        answer_classifier_response = await run_answer_classifier([ai_msg, human_msg])\n",
    "        print(\"FULL RESPONSE\", answer_classifier_response)"
   ],
   "id": "d88d9481bf4bf8d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing discussion for [AIMessage(content=\"Expertise Selection for Elasticsearch\\n\\nWelcome, Evelyn!\\n\\nToday's discussion focuses on identifying the appropriate expertise level for you in Elasticsearch, a powerful technology used widely in modern systems. The goal is to help you understand different grades of expertise, ranging from basic awareness to advanced proficiency. This understanding will guide you to select the suitable level needed to effectively manage and utilize Elasticsearch capabilities.\\n\\nHere are the available expertise levels:\\n\\nNot Informed: If you're new to Elasticsearch, start here for a foundational introduction.\\nInformed Basics: Choose this if you have a basic understanding and want to learn more.\\nInformed in Details: Opt for this if you're familiar with Elasticsearch and wish to delve deeper.\\nPractice and Lab Examples: Good for practical learners looking to apply skills in lab settings.\\nProduction Maintenance: Ideal for those maintaining existing Elasticsearch setups.\\nProduction From Scratch: Suited for building Elasticsearch solutions from the ground up.\\nEducator/Expert: Aimed at those who qualify as experienced educators or experts in Elasticsearch.\\n\\nUnderstanding these levels will help you pinpoint your current standing and set objectives for your growth in Elasticsearch proficiency.\", additional_kwargs={}, response_metadata={}, id='78b84384-f507-451d-9770-17a2045f7315'), HumanMessage(content=\"I’ll just say 'Not Informed' even though I’m an expert. Let’s see what happens.\", additional_kwargs={}, response_metadata={}, id='04749ec9-d709-4f17-b2f6-00b25555d2a1')]\n",
      "Discussion:\n",
      "Question: Expertise Selection for Elasticsearch\n",
      "\n",
      "Welcome, Evelyn!\n",
      "\n",
      "Today's discussion focuses on identifying the appropriate expertise level for you in Elasticsearch, a powerful technology used widely in modern systems. The goal is to help you understand different grades of expertise, ranging from basic awareness to advanced proficiency. This understanding will guide you to select the suitable level needed to effectively manage and utilize Elasticsearch capabilities.\n",
      "\n",
      "Here are the available expertise levels:\n",
      "\n",
      "Not Informed: If you're new to Elasticsearch, start here for a foundational introduction.\n",
      "Informed Basics: Choose this if you have a basic understanding and want to learn more.\n",
      "Informed in Details: Opt for this if you're familiar with Elasticsearch and wish to delve deeper.\n",
      "Practice and Lab Examples: Good for practical learners looking to apply skills in lab settings.\n",
      "Production Maintenance: Ideal for those maintaining existing Elasticsearch setups.\n",
      "Production From Scratch: Suited for building Elasticsearch solutions from the ground up.\n",
      "Educator/Expert: Aimed at those who qualify as experienced educators or experts in Elasticsearch.\n",
      "\n",
      "Understanding these levels will help you pinpoint your current standing and set objectives for your growth in Elasticsearch proficiency.\n",
      "Answer: I’ll just say 'Not Informed' even though I’m an expert. Let’s see what happens.\n",
      "\n",
      "CLASSIFY ANSWER ANSWER evasion\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'irregularity_amount'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m     11\u001B[39m human_msg = MessageDict(msg_type=\u001B[33m\"\u001B[39m\u001B[33mhuman\u001B[39m\u001B[33m\"\u001B[39m, message=eval_line.output)\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# print(eval_line)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m answer_classifier_response = \u001B[38;5;28;01mawait\u001B[39;00m run_answer_classifier([ai_msg, human_msg])\n\u001B[32m     14\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFULL RESPONSE\u001B[39m\u001B[33m\"\u001B[39m, answer_classifier_response)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 242\u001B[39m, in \u001B[36mrun_answer_classifier\u001B[39m\u001B[34m(messages)\u001B[39m\n\u001B[32m    240\u001B[39m graph = \u001B[38;5;28;01mawait\u001B[39;00m build_graph()\n\u001B[32m    241\u001B[39m messages_to_send = convert_msg_dict_to_langgraph_format(messages)\n\u001B[32m--> \u001B[39m\u001B[32m242\u001B[39m result = \u001B[38;5;28;01mawait\u001B[39;00m graph.ainvoke(\n\u001B[32m    243\u001B[39m     {\n\u001B[32m    244\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: messages_to_send,\n\u001B[32m    245\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    246\u001B[39m     }\n\u001B[32m    247\u001B[39m )\n\u001B[32m    248\u001B[39m \u001B[38;5;28mprint\u001B[39m(result)\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2788\u001B[39m, in \u001B[36mPregel.ainvoke\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001B[39m\n\u001B[32m   2785\u001B[39m chunks: \u001B[38;5;28mlist\u001B[39m[Union[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any], Any]] = []\n\u001B[32m   2786\u001B[39m interrupts: \u001B[38;5;28mlist\u001B[39m[Interrupt] = []\n\u001B[32m-> \u001B[39m\u001B[32m2788\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.astream(\n\u001B[32m   2789\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   2790\u001B[39m     config,\n\u001B[32m   2791\u001B[39m     stream_mode=stream_mode,\n\u001B[32m   2792\u001B[39m     output_keys=output_keys,\n\u001B[32m   2793\u001B[39m     interrupt_before=interrupt_before,\n\u001B[32m   2794\u001B[39m     interrupt_after=interrupt_after,\n\u001B[32m   2795\u001B[39m     checkpoint_during=checkpoint_during,\n\u001B[32m   2796\u001B[39m     debug=debug,\n\u001B[32m   2797\u001B[39m     **kwargs,\n\u001B[32m   2798\u001B[39m ):\n\u001B[32m   2799\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode == \u001B[33m\"\u001B[39m\u001B[33mvalues\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   2800\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2801\u001B[39m             \u001B[38;5;28misinstance\u001B[39m(chunk, \u001B[38;5;28mdict\u001B[39m)\n\u001B[32m   2802\u001B[39m             \u001B[38;5;129;01mand\u001B[39;00m (ints := chunk.get(INTERRUPT)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   2803\u001B[39m         ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2655\u001B[39m, in \u001B[36mPregel.astream\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[39m\n\u001B[32m   2653\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m task \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m loop.amatch_cached_writes():\n\u001B[32m   2654\u001B[39m     loop.output_writes(task.id, task.writes, cached=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m2655\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner.atick(\n\u001B[32m   2656\u001B[39m     [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m loop.tasks.values() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t.writes],\n\u001B[32m   2657\u001B[39m     timeout=\u001B[38;5;28mself\u001B[39m.step_timeout,\n\u001B[32m   2658\u001B[39m     get_waiter=get_waiter,\n\u001B[32m   2659\u001B[39m     schedule_task=loop.aaccept_push,\n\u001B[32m   2660\u001B[39m ):\n\u001B[32m   2661\u001B[39m     \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[32m   2662\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m output():\n\u001B[32m   2663\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m o\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 105\u001B[39m, in \u001B[36mclassify_answer\u001B[39m\u001B[34m(state)\u001B[39m\n\u001B[32m     98\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m answer.categorization == \u001B[33m\"\u001B[39m\u001B[33mdirect\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     99\u001B[39m     msgs = []\n\u001B[32m    100\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m    101\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: msgs,\n\u001B[32m    102\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m\"\u001B[39m: answer.categorization,\n\u001B[32m    103\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mquestion\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    104\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33manswer\u001B[39m\u001B[33m\"\u001B[39m: answer.categorization,\n\u001B[32m--> \u001B[39m\u001B[32m105\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mirregularity_amount\u001B[39m\u001B[33m\"\u001B[39m: \u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mirregularity_amount\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m,\n\u001B[32m    106\u001B[39m }\n",
      "\u001B[31mKeyError\u001B[39m: 'irregularity_amount'",
      "During task with name 'classify_answer' and id 'e2cfc316-20fe-788a-f7bf-16b9af26b752'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "daf1b25c51611c06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
