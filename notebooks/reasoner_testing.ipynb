{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T12:22:50.941316Z",
     "start_time": "2025-06-24T12:22:50.010316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from db.db import get_session\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from typing import TypedDict, Annotated, Optional, Literal, Any, List, AsyncGenerator\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from openai.resources.containers.files import content\n",
    "from psycopg_pool import AsyncConnectionPool\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import add_messages\n",
    "from langgraph.types import interrupt, Command\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from agents.guidance import build_graph, provide_guidance, GuidanceHelperStdOutput\n",
    "from agents.saver import PGSaver\n",
    "from dto.response.grades import GradeResponseBase\n",
    "from dto.response.matrix_chats import MessageDict\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.getenv(\"PG_VECTOR_DATABASE_URL\")\n",
    "\n",
    "LITE_LLM_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# LITE_LLM_URL = os.getenv(\"OPENAI_BASE_URL\")\n",
    "# LITE_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "\n",
    "# model = ChatOpenAI(model=LITE_MODEL, api_key=LITE_LLM_API_KEY, base_url=LITE_LLM_URL)\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\", api_key=LITE_LLM_API_KEY, streaming=True, verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "class AmbiguousStdOutput(BaseModel):\n",
    "    is_ambiguous: bool\n",
    "    question: str\n",
    "\n",
    "\n",
    "class FinalClassificationStdOutput(BaseModel):\n",
    "    final_class: str = Field(description=\"Final classification label\")\n",
    "    final_class_id: int = Field(description=\"Id of the final classification\")\n",
    "    message_to_the_user: str = Field(description=\"Message to user\")\n",
    "\n",
    "\n",
    "class SpellcheckBase(BaseModel):\n",
    "    spelling: str\n",
    "    corrected_spelling: str\n",
    "    correction_applied: bool\n",
    "\n",
    "\n",
    "class ReasonerOutputBase(BaseModel):\n",
    "    classification: str\n",
    "    classification_explanation: str\n",
    "    certainty_level: int\n",
    "\n",
    "\n",
    "class ReasonerState(TypedDict):\n",
    "    grades: List[GradeResponseBase]\n",
    "    messages: Annotated[list, add_messages]\n",
    "    spellcheck_response: Optional[SpellcheckBase]\n",
    "    reasoner_response: Optional[ReasonerOutputBase]\n",
    "    interrupt_state: dict[str, str]\n",
    "    is_ambiguous: bool\n",
    "    ambiguous_output: Optional[str]\n",
    "    should_admin_continue: bool\n",
    "    number_of_irregularities: Optional[int]\n",
    "    final_result: Optional[FinalClassificationStdOutput]\n",
    "\n",
    "\n",
    "class ClassifierState(TypedDict):\n",
    "    grades: List[GradeResponseBase]\n",
    "    msgs: Annotated[list, add_messages]\n",
    "    finished_state: Optional[str]\n",
    "    interrupt_state: dict[str, str]\n",
    "\n",
    "\n",
    "classifier_builder = StateGraph(ClassifierState)\n",
    "\n",
    "\n",
    "async def reasoner(state: ClassifierState) -> ClassifierState:\n",
    "    message = ChatPromptTemplate.from_messages(\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Based on the user question you need to categorize into one of the following categories:\n",
    "            {categories}\n",
    "            Respond only with the category recognized!\n",
    "            \"\"\",\n",
    "        )\n",
    "    )\n",
    "    msg = message.format(categories=state[\"grades\"])\n",
    "    model_structured = model.with_structured_output(ReasonerOutputBase)\n",
    "    response = await model_structured.ainvoke(state[\"msgs\"] + [msg])\n",
    "    return {\n",
    "        \"msgs\": [AIMessage(response.classification)],\n",
    "        \"finished_state\": None,\n",
    "        \"grades\": state[\"grades\"],\n",
    "        \"interrupt_state\": {},\n",
    "    }\n",
    "\n",
    "\n",
    "async def reflect(state: ClassifierState) -> ClassifierState:\n",
    "    input_val = state[\"msgs\"][-2].content\n",
    "    predicted_state = state[\"msgs\"][-1].content\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an reviewing user submission categorization of the answer of expertise in a particular subject.\n",
    "        You are provided the available expertise categories to which you need to categorize into.\n",
    "        Critique the prediction if you think it's incorrect!\n",
    "        If you agree with correct prediction respond with exactly \"finish\" without any explanations!\n",
    "        If you find the categorization inconclusive or not indicative in any way of the user message respond with exactly \"human\"!\n",
    "        Expertise categories:\n",
    "        {categories}\n",
    "        Users message: {msg}\n",
    "        Predicted user expertise: {state}\n",
    "        \"\"\"\n",
    "    )\n",
    "    prompt = await prompt_template.ainvoke(\n",
    "        {\"state\": predicted_state, \"msg\": input_val, \"categories\": state[\"grades\"]}\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    print(\"REFLECT RESPONSE\", response)\n",
    "    return {\n",
    "        \"msgs\": [HumanMessage(response.content)],\n",
    "        \"finished_state\": None,\n",
    "        \"grades\": state[\"grades\"],\n",
    "        \"interrupt_state\": {},\n",
    "    }\n",
    "\n",
    "\n",
    "async def correct_found(\n",
    "    state: ClassifierState,\n",
    ") -> Literal[\"reasoner\", \"human\", \"finish\"]:\n",
    "    if state[\"msgs\"][-1].content == \"finish\":\n",
    "        print(\"CORRECT RESPONSE finish\")\n",
    "        return \"finish\"\n",
    "    elif state[\"msgs\"][-1].content == \"human\":\n",
    "        print(\"CORRECT RESPONSE human\")\n",
    "        return \"human\"\n",
    "    print(\"CORRECT RESPONSE reasoner\")\n",
    "    return \"reasoner\"\n",
    "\n",
    "\n",
    "async def finish(state: ClassifierState) -> ClassifierState:\n",
    "    finished_state = state[\"msgs\"][-2].content\n",
    "    return {\n",
    "        \"msgs\": state[\"msgs\"],\n",
    "        \"finished_state\": finished_state,\n",
    "        \"grades\": state[\"grades\"],\n",
    "        \"interrupt_state\": {},\n",
    "    }\n",
    "\n",
    "\n",
    "async def human(state: ClassifierState) -> ClassifierState:\n",
    "    interrupt_val = {\n",
    "        \"answer_to_revisit\": state[\"msgs\"][-2].content,\n",
    "    }\n",
    "    value = interrupt(\n",
    "        interrupt_val,\n",
    "    )\n",
    "    print(\"HUMAN IN THE LOOP RESPONSE\")\n",
    "    return {\n",
    "        \"msgs\": [AIMessage(value)],\n",
    "        \"finished_state\": state[\"finished_state\"],\n",
    "        \"grades\": state[\"grades\"],\n",
    "        \"interrupt_state\": interrupt_val,\n",
    "    }\n",
    "\n",
    "\n",
    "classifier_builder.add_node(\"reasoner\", reasoner)\n",
    "classifier_builder.add_node(\"reflect\", reflect)\n",
    "classifier_builder.add_node(\"finish\", finish)\n",
    "classifier_builder.add_node(\"human\", human)\n",
    "classifier_builder.add_edge(START, \"reasoner\")\n",
    "classifier_builder.add_edge(\"reasoner\", \"reflect\")\n",
    "classifier_builder.add_conditional_edges(\"reflect\", correct_found)\n",
    "classifier_builder.add_edge(\"reflect\", \"finish\")\n",
    "classifier_builder.add_edge(\"human\", \"finish\")\n",
    "classifier_builder.add_edge(\"finish\", END)\n",
    "\n",
    "classify = classifier_builder.compile()\n",
    "\n",
    "builder = StateGraph(ReasonerState)\n",
    "\n",
    "\n",
    "async def answer_classifier(state: ReasonerState) -> ReasonerState:\n",
    "    response: GuidanceHelperStdOutput = None\n",
    "    async for chunk in provide_guidance(state[\"messages\"]):\n",
    "        print(\"ANSWER RESPONSE\", chunk)\n",
    "        if \"structured_response\" in chunk:\n",
    "            if isinstance(chunk[\"structured_response\"], GuidanceHelperStdOutput):\n",
    "                response = chunk[\"structured_response\"]\n",
    "    print(\"GUIDANCE RESPONSE\", response)\n",
    "    # guidance_graph = await build_graph()\n",
    "    # irregularities_num = 0\n",
    "    # if \"number_of_irregularities\" in state:\n",
    "    #     if state[\"number_of_irregularities\"] is None:\n",
    "    #         irregularities_num = 0\n",
    "    # response = await guidance_graph.ainvoke(\n",
    "    #     {\n",
    "    #         \"messages\": state[\"messages\"],\n",
    "    #         \"irregularity_amount\": irregularities_num,\n",
    "    #     }\n",
    "    # )\n",
    "    # message_to_respond = []\n",
    "    # if len(response[\"messages\"]) > 0:\n",
    "    #     message_to_respond = [response[\"messages\"][-1]]\n",
    "    #\n",
    "    # print(\"ANSWER CATEGORIZATION\", response)\n",
    "\n",
    "    return {\n",
    "        \"grades\": state[\"grades\"],\n",
    "        \"messages\": [AIMessage(response.message)],\n",
    "        \"number_of_irregularities\": 0,\n",
    "        \"spellcheck_response\": None,\n",
    "        \"reasoner_response\": None,\n",
    "        \"interrupt_state\": {},\n",
    "        \"is_ambiguous\": False,\n",
    "        \"ambiguous_output\": \"direct\" if response.has_user_answered else \"indirect\",\n",
    "        \"should_admin_continue\": response.should_admin_be_involved,\n",
    "        \"final_result\": None,\n",
    "    }\n",
    "\n",
    "\n",
    "async def next_step(\n",
    "    state: ReasonerState,\n",
    ") -> Literal[\"deeply_classify\", \"ask_clarification\", \"human\"]:\n",
    "    print(\"NEXT STEP\")\n",
    "    print(f\"{state}\")\n",
    "    if state[\"should_admin_continue\"]:\n",
    "        return \"human\"\n",
    "    if state[\"ambiguous_output\"] != \"direct\":\n",
    "        return \"ask_clarification\"\n",
    "    return \"deeply_classify\"\n",
    "\n",
    "\n",
    "async def ask_clarification(state: ReasonerState) -> ReasonerState:\n",
    "    print(\"Ask clarification\")\n",
    "    interrupt_val = {\n",
    "        \"answer_to_revisit\": state[\"messages\"][-2].content,\n",
    "    }\n",
    "    interrupt_msg = interrupt(interrupt_val)\n",
    "    return {\n",
    "        \"grades\": state[\"grades\"],\n",
    "        \"messages\": [AIMessage(interrupt_msg)],\n",
    "        \"spellcheck_response\": state[\"spellcheck_response\"],\n",
    "        \"reasoner_response\": None,\n",
    "        \"interrupt_state\": interrupt_val,\n",
    "        \"is_ambiguous\": state[\"is_ambiguous\"],\n",
    "        \"ambiguous_output\": state[\"ambiguous_output\"],\n",
    "        \"number_of_irregularities\": state[\"number_of_irregularities\"],\n",
    "        \"should_admin_continue\": state[\"should_admin_continue\"],\n",
    "        \"final_result\": None,\n",
    "    }\n",
    "\n",
    "\n",
    "async def deeply_classify(state: ReasonerState) -> ReasonerState:\n",
    "    print(\"Deeply classify\")\n",
    "    async for class_chunk in classify.astream(\n",
    "        {\"msgs\": state[\"messages\"], \"finished_state\": None, \"grades\": state[\"grades\"]}\n",
    "    ):\n",
    "        if (\n",
    "            \"finished_state\" in class_chunk\n",
    "            and class_chunk[\"finished_state\"] is not None\n",
    "        ):\n",
    "            msg = class_chunk[\"finished_state\"]\n",
    "    return {\n",
    "        \"grades\": state[\"grades\"],\n",
    "        \"messages\": [],\n",
    "        \"spellcheck_response\": state[\"spellcheck_response\"],\n",
    "        \"reasoner_response\": state[\"reasoner_response\"],\n",
    "        \"interrupt_state\": {},\n",
    "        \"is_ambiguous\": state[\"is_ambiguous\"],\n",
    "        \"ambiguous_output\": state[\"ambiguous_output\"],\n",
    "        \"number_of_irregularities\": state[\"number_of_irregularities\"],\n",
    "        \"should_admin_continue\": state[\"should_admin_continue\"],\n",
    "        \"final_result\": None,\n",
    "    }\n",
    "\n",
    "\n",
    "async def reasoner(state: ReasonerState) -> ReasonerState:\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Summarize the conversation and thank the user and show the finalized categorization emphasized!\n",
    "        Use one of these categories, labels only, do not display the entire object:\n",
    "        {grades}\n",
    "        Do not explain yourself and prolong the conversation!\n",
    "        \"\"\"\n",
    "    )\n",
    "    prompt = prompt_template.invoke({\"grades\": state[\"grades\"]})\n",
    "    structured_output_model = model.with_structured_output(FinalClassificationStdOutput)\n",
    "    response = structured_output_model.invoke(\n",
    "        state[\"messages\"] + [HumanMessage(prompt.to_string())]\n",
    "    )\n",
    "    print(\"REASONER RESPONSE -> \", response)\n",
    "    return {\n",
    "        \"grades\": state[\"grades\"],\n",
    "        \"messages\": [],\n",
    "        \"spellcheck_response\": state[\"spellcheck_response\"],\n",
    "        \"reasoner_response\": state[\"reasoner_response\"],\n",
    "        \"interrupt_state\": {},\n",
    "        \"is_ambiguous\": state[\"is_ambiguous\"],\n",
    "        \"ambiguous_output\": state[\"ambiguous_output\"],\n",
    "        \"number_of_irregularities\": state[\"number_of_irregularities\"],\n",
    "        \"should_admin_continue\": state[\"should_admin_continue\"],\n",
    "        \"final_result\": response,\n",
    "    }\n",
    "\n",
    "\n",
    "async def human(state: ReasonerState) -> ReasonerState:\n",
    "    print(\"HUMAN IN THE LOOP\")\n",
    "    interrupt_val = {\n",
    "        \"answer_to_revisit\": state[\"messages\"][-2].content,\n",
    "    }\n",
    "    value = interrupt(\n",
    "        interrupt_val,\n",
    "    )\n",
    "    print(\"HUMAN IN THE LOOP RESPONSE\")\n",
    "    return {\n",
    "        \"grades\": state[\"grades\"],\n",
    "        \"messages\": [value],\n",
    "        \"spellcheck_response\": state[\"spellcheck_response\"],\n",
    "        \"reasoner_response\": state[\"reasoner_response\"],\n",
    "        \"interrupt_state\": {},\n",
    "        \"is_ambiguous\": state[\"is_ambiguous\"],\n",
    "        \"ambiguous_output\": state[\"ambiguous_output\"],\n",
    "        \"number_of_irregularities\": state[\"number_of_irregularities\"],\n",
    "        \"should_admin_continue\": True,\n",
    "        \"final_result\": state[\"final_result\"],\n",
    "    }\n",
    "\n",
    "\n",
    "builder.add_node(\"answer_classifier\", answer_classifier)\n",
    "builder.add_node(\"ask_clarification\", ask_clarification)\n",
    "builder.add_node(\"deeply_classify\", deeply_classify)\n",
    "builder.add_node(\"human\", human)\n",
    "builder.add_node(\"reasoner\", reasoner)\n",
    "builder.add_edge(START, \"answer_classifier\")\n",
    "builder.add_conditional_edges(\"answer_classifier\", next_step)\n",
    "builder.add_edge(\"ask_clarification\", \"deeply_classify\")\n",
    "builder.add_edge(\"deeply_classify\", \"reasoner\")\n",
    "builder.add_edge(\"human\", \"deeply_classify\")\n",
    "builder.add_edge(\"reasoner\", END)\n",
    "\n",
    "full_graph = builder.compile()\n",
    "\n",
    "\n",
    "async def get_graph() -> AsyncGenerator[CompiledStateGraph, Any]:\n",
    "    async with AsyncConnectionPool(db_url) as conn:\n",
    "        checkpointer = PGSaver(get_session)\n",
    "        graph = builder.compile(checkpointer=checkpointer)\n",
    "        yield graph\n",
    "\n",
    "\n",
    "async def reasoner_run(\n",
    "    thread_id: uuid.UUID, msgs: List[MessageDict], grades: List[GradeResponseBase]\n",
    ") -> AsyncGenerator[str, Any]:\n",
    "    async for graph in get_graph():\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        interrupt_happened = False\n",
    "        interrupt_value = \"\"\n",
    "        processing_type = \"\"\n",
    "        message_val = \"\"\n",
    "        should_admin_continue = False\n",
    "        async for chunk in graph.astream(\n",
    "            {\n",
    "                \"messages\": msgs,\n",
    "                \"grades\": grades,\n",
    "            },\n",
    "            config,\n",
    "        ):\n",
    "            actual_type = list(chunk.keys())[0]\n",
    "            print(\"async chunk\", chunk)\n",
    "            print(\"ACTUAL TYPE\", actual_type)\n",
    "            if actual_type == \"answer_classifier\":\n",
    "                processing_type = \"Classifying answer\"\n",
    "            elif actual_type == \"ambiguity\":\n",
    "                processing_type = \"Resolving ambiguity\"\n",
    "            elif actual_type == \"__interrupt__\":\n",
    "                processing_type = \"Interrupt\"\n",
    "            elif actual_type == \"deeply_classify\":\n",
    "                processing_type = \"Classifying\"\n",
    "            elif actual_type == \"reasoner\":\n",
    "                processing_type = \"Finalizing\"\n",
    "            print(\"PROCESSING TYPE\", processing_type)\n",
    "            if \"__interrupt__\" in chunk:\n",
    "                print(f\"INTERRUPT RESPONSE {chunk}\")\n",
    "                interrupt_happened = True\n",
    "                interrupt_value = chunk[\"__interrupt__\"][0].value[\"answer_to_revisit\"]\n",
    "                message_val = \"\"\n",
    "            else:\n",
    "                should_admin_continue = chunk[actual_type][\"should_admin_continue\"]\n",
    "                if \"final_result\" in chunk[actual_type] is not None:\n",
    "                    if hasattr(\n",
    "                        chunk[actual_type][\"final_result\"], \"message_to_the_user\"\n",
    "                    ):\n",
    "                        message_val = chunk[actual_type][\n",
    "                            \"final_result\"\n",
    "                        ].message_to_the_user\n",
    "                if len(chunk[actual_type][\"messages\"]) > 0:\n",
    "                    print(\"WHY DO MESSAGES NEVER GO IN\")\n",
    "                    message_val = chunk[actual_type][\"messages\"][-1].content\n",
    "                    print(f\"MESSAGE VAL {message_val}\")\n",
    "\n",
    "            yield json.dumps(\n",
    "                {\n",
    "                    \"type\": processing_type,\n",
    "                    \"interrupt_happened\": interrupt_happened,\n",
    "                    \"interrupt_value\": interrupt_value,\n",
    "                    \"message\": message_val,\n",
    "                    \"final_result\": (\n",
    "                        chunk[actual_type][\"final_result\"].model_dump_json()\n",
    "                        if \"final_result\" in chunk[actual_type]\n",
    "                        and isinstance(\n",
    "                            chunk[actual_type][\"final_result\"],\n",
    "                            FinalClassificationStdOutput,\n",
    "                        )\n",
    "                        else \"\"\n",
    "                    ),\n",
    "                    \"should_admin_continue\": should_admin_continue,\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "async def run_interrupted(thread_id: uuid.UUID, unblock_value: str):\n",
    "    async for graph in get_graph():\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        state = await graph.aget_state(config)\n",
    "        unblock_response = await graph.ainvoke(\n",
    "            Command(resume=unblock_value), config=config\n",
    "        )\n",
    "        return unblock_response\n"
   ],
   "id": "d451a071dae549fa",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T12:22:58.017840Z",
     "start_time": "2025-06-24T12:22:52.057856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.common import convert_msg_dict_to_langgraph_format\n",
    "import asyncio\n",
    "\n",
    "grades: List[GradeResponseBase] = [\n",
    "    GradeResponseBase(\n",
    "        id=1,\n",
    "        label=\"Not Informed\",\n",
    "        value=1\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=2,\n",
    "        label=\"Informed Basics\",\n",
    "        value=2\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=3,\n",
    "        label=\"Informed in Details\",\n",
    "        value=3\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=4,\n",
    "        label=\"Practice and Lab Examples\",\n",
    "        value=4\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=5,\n",
    "        label=\"Production Maintenance\",\n",
    "        value=5\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=6,\n",
    "        label=\"Production from Scratch\",\n",
    "        value=6\n",
    "    ),\n",
    "    GradeResponseBase(\n",
    "        id=7,\n",
    "        label=\"Educator/Expert\",\n",
    "        value=7\n",
    "    ),\n",
    "]\n",
    "\n",
    "msgs: List[MessageDict] = [\n",
    "    MessageDict(\n",
    "        msg_type=\"ai\",\n",
    "        message=\"\"\"\n",
    "        Expertise in Cryptography\n",
    "        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\n",
    "\n",
    "        We offer various expertise grades to help you identify where you stand or where you want to grow:\n",
    "\n",
    "        Not Informed - Basic understanding of the subject.\n",
    "        Informed Basics - Familiarity with fundamental concepts.\n",
    "        Informed in Details - Comprehensive knowledge of the topic.\n",
    "        Practice and Lab Examples - Practical experience and demonstration.\n",
    "        Production Maintenance - Hands-on experience in maintaining production systems.\n",
    "        Production from Scratch - Ability to build production systems from the ground up.\n",
    "        Educator/Expert - Mastery of the subject, capable of teaching others.\n",
    "        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessageDict(\n",
    "        msg_type=\"human\",\n",
    "        message=\"\"\"\n",
    "        bla bla bla\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessageDict(\n",
    "        msg_type=\"ai\",\n",
    "        message=\"\"\"\n",
    "        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\n",
    "\n",
    "If this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessageDict(\n",
    "        msg_type=\"human\",\n",
    "        message=\"\"\"\n",
    "        Working great\n",
    "        \"\"\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "messages_to_send = convert_msg_dict_to_langgraph_format(msgs)\n",
    "\n",
    "def completed_task(result):\n",
    "    print(\"COMPLETED TASK:\", result.result())\n",
    "\n",
    "async def main():\n",
    "    # Get the current running loop\n",
    "    loop = asyncio.get_running_loop()\n",
    "    thread_id = uuid.uuid4()\n",
    "    print(\"STARTING TESTING\")\n",
    "    print(\"THREAD ID:\", thread_id)\n",
    "    async for result in reasoner_run(thread_id, messages_to_send, grades):\n",
    "        yield result\n",
    "\n",
    "async for result in main():\n",
    "    print(\"RESULT:\", result)"
   ],
   "id": "d521670130d4d69a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TESTING\n",
      "THREAD ID: de99a266-6a01-4dae-b322-33f4e3c7ce48\n",
      "def aget_tuple ->\n",
      "{'tags': [], 'metadata': ChainMap({}), 'callbacks': None, 'recursion_limit': 25, 'configurable': {'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48'}}\n",
      "404: Not found\n",
      "def aput ->\n",
      "CONFIG {'tags': [], 'metadata': ChainMap({}), 'callbacks': None, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': '', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', 'checkpoint_id': None}}\n",
      "CHECKPOINT {'v': 3, 'ts': '2025-06-24T12:22:52.183651+00:00', 'id': '1f050f5f-2f4f-6c06-bfff-1a4c97ac89e8', 'channel_values': {'__start__': {'messages': [AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={})], 'grades': [GradeResponseBase(id=1, label='Not Informed', value=1), GradeResponseBase(id=2, label='Informed Basics', value=2), GradeResponseBase(id=3, label='Informed in Details', value=3), GradeResponseBase(id=4, label='Practice and Lab Examples', value=4), GradeResponseBase(id=5, label='Production Maintenance', value=5), GradeResponseBase(id=6, label='Production from Scratch', value=6), GradeResponseBase(id=7, label='Educator/Expert', value=7)]}}, 'channel_versions': {'__start__': 1}, 'versions_seen': {'__input__': {}}, 'pending_sends': []}\n",
      "METADATA {'source': 'input', 'writes': {'__start__': {'messages': [AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={})], 'grades': [GradeResponseBase(id=1, label='Not Informed', value=1), GradeResponseBase(id=2, label='Informed Basics', value=2), GradeResponseBase(id=3, label='Informed in Details', value=3), GradeResponseBase(id=4, label='Practice and Lab Examples', value=4), GradeResponseBase(id=5, label='Production Maintenance', value=5), GradeResponseBase(id=6, label='Production from Scratch', value=6), GradeResponseBase(id=7, label='Educator/Expert', value=7)]}}, 'step': -1, 'parents': {}}\n",
      "NEW_VERSIONS {'__start__': 1}\n",
      "def aput_writes ->\n",
      "{'tags': [], 'metadata': ChainMap({}), 'callbacks': None, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': '', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', 'checkpoint_id': '1f050f5f-2f4f-6c06-bfff-1a4c97ac89e8'}} deque([('messages', [AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={})]), ('grades', [GradeResponseBase(id=1, label='Not Informed', value=1), GradeResponseBase(id=2, label='Informed Basics', value=2), GradeResponseBase(id=3, label='Informed in Details', value=3), GradeResponseBase(id=4, label='Practice and Lab Examples', value=4), GradeResponseBase(id=5, label='Production Maintenance', value=5), GradeResponseBase(id=6, label='Production from Scratch', value=6), GradeResponseBase(id=7, label='Educator/Expert', value=7)]), ('branch:to:answer_classifier', None)]) 556e9715-d32c-9dd4-3b02-4bf8142fe9cf ~__pregel_pull, __start__\n",
      "def aput ->\n",
      "CONFIG {'tags': [], 'metadata': ChainMap({}), 'callbacks': None, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': '', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', 'checkpoint_id': '1f050f5f-2f4f-6c06-bfff-1a4c97ac89e8'}}\n",
      "CHECKPOINT {'v': 3, 'ts': '2025-06-24T12:22:52.184355+00:00', 'id': '1f050f5f-2f51-6786-8000-242d101f1c70', 'channel_values': {'grades': [GradeResponseBase(id=1, label='Not Informed', value=1), GradeResponseBase(id=2, label='Informed Basics', value=2), GradeResponseBase(id=3, label='Informed in Details', value=3), GradeResponseBase(id=4, label='Practice and Lab Examples', value=4), GradeResponseBase(id=5, label='Production Maintenance', value=5), GradeResponseBase(id=6, label='Production from Scratch', value=6), GradeResponseBase(id=7, label='Educator/Expert', value=7)], 'messages': [AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='114f5739-696c-410c-b0f8-45fbe4131492'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='150ac1ed-dbec-4829-8265-7c44b297cc23'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='c16a4480-db75-45be-9284-fbef8efd9f2a')], 'branch:to:answer_classifier': None}, 'channel_versions': {'__start__': 2, 'messages': 2, 'grades': 2, 'branch:to:answer_classifier': 2}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}}, 'pending_sends': []}\n",
      "METADATA {'source': 'loop', 'writes': None, 'step': 0, 'parents': {}}\n",
      "NEW_VERSIONS {'__start__': 2, 'messages': 2, 'grades': 2, 'branch:to:answer_classifier': 2}\n",
      "def aget_tuple ->\n",
      "{'tags': [], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x10c3e15b0>, 'recursion_limit': 25, 'configurable': {'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', '__pregel_task_id': '9147a212-11b7-e301-baed-48166296ca5c', '__pregel_send': <built-in method extend of collections.deque object at 0x10c408e50>, '__pregel_read': functools.partial(<function local_read at 0x10a196b60>, {'grades': <langgraph.channels.last_value.LastValue object at 0x10bf37780>, 'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x10c01e340>, 'spellcheck_response': <langgraph.channels.last_value.LastValue object at 0x10becd700>, 'reasoner_response': <langgraph.channels.last_value.LastValue object at 0x10bff4940>, 'interrupt_state': <langgraph.channels.last_value.LastValue object at 0x10bff41c0>, 'is_ambiguous': <langgraph.channels.last_value.LastValue object at 0x10bc858c0>, 'ambiguous_output': <langgraph.channels.last_value.LastValue object at 0x10c3f3440>, 'should_admin_continue': <langgraph.channels.last_value.LastValue object at 0x10bdfbf80>, 'number_of_irregularities': <langgraph.channels.last_value.LastValue object at 0x10be2f080>, 'final_result': <langgraph.channels.last_value.LastValue object at 0x10be2f400>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7a80>, 'branch:to:answer_classifier': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7280>, 'branch:to:ask_clarification': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cc00>, 'branch:to:deeply_classify': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cdc0>, 'branch:to:human': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cb00>, 'branch:to:reasoner': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10beed680>}, {}, PregelTaskWrites(path=('__pregel_pull', 'answer_classifier'), name='answer_classifier', writes=deque([]), triggers=('branch:to:answer_classifier',))), '__pregel_store': None, '__pregel_checkpointer': <agents.saver.PGSaver object at 0x10bc7c980>, 'checkpoint_map': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'checkpoint_id': None, 'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', '__pregel_scratchpad': PregelScratchpad(call_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9030>, interrupt_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe8d30>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x10c4153a0>, resume=[], subgraph_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9060>), '__pregel_previous': None, '__pregel_call': functools.partial(<function _acall at 0x10a1c4d60>, <weakref at 0x10bc98090; to 'langgraph.types.PregelExecutableTask' at 0x10c415450>, stream=False, retry=None, futures=<weakref at 0x10bc9b9c0; to 'langgraph.pregel.runner.FuturesDict' at 0x10bc9a490>, schedule_task=<bound method AsyncPregelLoop.aaccept_push of <langgraph.pregel.loop.AsyncPregelLoop object at 0x10be278c0>>, submit=<weakref at 0x10bfc9850; to 'langgraph.pregel.executor.AsyncBackgroundExecutor' at 0x10bfbc1a0>, loop=<_UnixSelectorEventLoop running=True closed=False debug=False>)}}\n",
      "404: Not found\n",
      "def aput ->\n",
      "CONFIG {'tags': [], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x10c3e15b0>, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', '__pregel_task_id': '9147a212-11b7-e301-baed-48166296ca5c', '__pregel_send': <built-in method extend of collections.deque object at 0x10c408e50>, '__pregel_read': functools.partial(<function local_read at 0x10a196b60>, {'grades': <langgraph.channels.last_value.LastValue object at 0x10bf37780>, 'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x10c01e340>, 'spellcheck_response': <langgraph.channels.last_value.LastValue object at 0x10becd700>, 'reasoner_response': <langgraph.channels.last_value.LastValue object at 0x10bff4940>, 'interrupt_state': <langgraph.channels.last_value.LastValue object at 0x10bff41c0>, 'is_ambiguous': <langgraph.channels.last_value.LastValue object at 0x10bc858c0>, 'ambiguous_output': <langgraph.channels.last_value.LastValue object at 0x10c3f3440>, 'should_admin_continue': <langgraph.channels.last_value.LastValue object at 0x10bdfbf80>, 'number_of_irregularities': <langgraph.channels.last_value.LastValue object at 0x10be2f080>, 'final_result': <langgraph.channels.last_value.LastValue object at 0x10be2f400>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7a80>, 'branch:to:answer_classifier': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7280>, 'branch:to:ask_clarification': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cc00>, 'branch:to:deeply_classify': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cdc0>, 'branch:to:human': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cb00>, 'branch:to:reasoner': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10beed680>}, {}, PregelTaskWrites(path=('__pregel_pull', 'answer_classifier'), name='answer_classifier', writes=deque([]), triggers=('branch:to:answer_classifier',))), '__pregel_store': None, '__pregel_checkpointer': <agents.saver.PGSaver object at 0x10bc7c980>, 'checkpoint_map': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'checkpoint_id': None, '__pregel_scratchpad': PregelScratchpad(call_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9030>, interrupt_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe8d30>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x10c4153a0>, resume=[], subgraph_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9060>), '__pregel_previous': None, '__pregel_call': functools.partial(<function _acall at 0x10a1c4d60>, <weakref at 0x10bc98090; to 'langgraph.types.PregelExecutableTask' at 0x10c415450>, stream=False, retry=None, futures=<weakref at 0x10bc9b9c0; to 'langgraph.pregel.runner.FuturesDict' at 0x10bc9a490>, schedule_task=<bound method AsyncPregelLoop.aaccept_push of <langgraph.pregel.loop.AsyncPregelLoop object at 0x10be278c0>>, submit=<weakref at 0x10bfc9850; to 'langgraph.pregel.executor.AsyncBackgroundExecutor' at 0x10bfbc1a0>, loop=<_UnixSelectorEventLoop running=True closed=False debug=False>)}}\n",
      "CHECKPOINT {'v': 3, 'ts': '2025-06-24T12:22:52.207902+00:00', 'id': '1f050f5f-2f8a-6f54-bfff-90ef24c6c322', 'channel_values': {'__start__': {'messages': [SystemMessage(content='\\n    You are helping the user to properly grade their expertise in the mentioned field.\\n    Everything you help him with should be done by utilizing the tools or around the topic\\n    of helping him populate his expertise level on the topic.\\n    Do not discuss anything except from the provided context.\\n    You are guiding the user to evaluate himself on provided topic.\\n    Do not discuss anything (any other topic) except from the ones provided in topic!\\n    Do not chat about other topics with the user, guide him how to populate his expertise with the grades provided\\n    Warn the user if answering with unrelated topics or evading to answer the question will be escalated by involving managers!\\n    Topic: {context}\\n    If the user is evading to answer the question and is not asking any questions related to the topic for 4 or 5 messages\\n    please involve admin\\n    When the user answers with proper categorization of skills return only that categorization!\\n    ', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='114f5739-696c-410c-b0f8-45fbe4131492'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='150ac1ed-dbec-4829-8265-7c44b297cc23'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='c16a4480-db75-45be-9284-fbef8efd9f2a')], 'context': AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), 'intermediate_steps': []}}, 'channel_versions': {'__start__': 1}, 'versions_seen': {'__input__': {}}, 'pending_sends': []}\n",
      "METADATA {'source': 'input', 'writes': {'__start__': {'messages': [SystemMessage(content='\\n    You are helping the user to properly grade their expertise in the mentioned field.\\n    Everything you help him with should be done by utilizing the tools or around the topic\\n    of helping him populate his expertise level on the topic.\\n    Do not discuss anything except from the provided context.\\n    You are guiding the user to evaluate himself on provided topic.\\n    Do not discuss anything (any other topic) except from the ones provided in topic!\\n    Do not chat about other topics with the user, guide him how to populate his expertise with the grades provided\\n    Warn the user if answering with unrelated topics or evading to answer the question will be escalated by involving managers!\\n    Topic: {context}\\n    If the user is evading to answer the question and is not asking any questions related to the topic for 4 or 5 messages\\n    please involve admin\\n    When the user answers with proper categorization of skills return only that categorization!\\n    ', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='114f5739-696c-410c-b0f8-45fbe4131492'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='150ac1ed-dbec-4829-8265-7c44b297cc23'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='c16a4480-db75-45be-9284-fbef8efd9f2a')], 'context': AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), 'intermediate_steps': []}}, 'step': -1, 'parents': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}\n",
      "NEW_VERSIONS {'__start__': 1}\n",
      "def aput_writes ->\n",
      "{'tags': [], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x10c3e15b0>, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', '__pregel_task_id': '9147a212-11b7-e301-baed-48166296ca5c', '__pregel_send': <built-in method extend of collections.deque object at 0x10c408e50>, '__pregel_read': functools.partial(<function local_read at 0x10a196b60>, {'grades': <langgraph.channels.last_value.LastValue object at 0x10bf37780>, 'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x10c01e340>, 'spellcheck_response': <langgraph.channels.last_value.LastValue object at 0x10becd700>, 'reasoner_response': <langgraph.channels.last_value.LastValue object at 0x10bff4940>, 'interrupt_state': <langgraph.channels.last_value.LastValue object at 0x10bff41c0>, 'is_ambiguous': <langgraph.channels.last_value.LastValue object at 0x10bc858c0>, 'ambiguous_output': <langgraph.channels.last_value.LastValue object at 0x10c3f3440>, 'should_admin_continue': <langgraph.channels.last_value.LastValue object at 0x10bdfbf80>, 'number_of_irregularities': <langgraph.channels.last_value.LastValue object at 0x10be2f080>, 'final_result': <langgraph.channels.last_value.LastValue object at 0x10be2f400>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7a80>, 'branch:to:answer_classifier': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7280>, 'branch:to:ask_clarification': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cc00>, 'branch:to:deeply_classify': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cdc0>, 'branch:to:human': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cb00>, 'branch:to:reasoner': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10beed680>}, {}, PregelTaskWrites(path=('__pregel_pull', 'answer_classifier'), name='answer_classifier', writes=deque([]), triggers=('branch:to:answer_classifier',))), '__pregel_store': None, '__pregel_checkpointer': <agents.saver.PGSaver object at 0x10bc7c980>, 'checkpoint_map': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'checkpoint_id': '1f050f5f-2f8a-6f54-bfff-90ef24c6c322', '__pregel_scratchpad': PregelScratchpad(call_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9030>, interrupt_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe8d30>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x10c4153a0>, resume=[], subgraph_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9060>), '__pregel_previous': None, '__pregel_call': functools.partial(<function _acall at 0x10a1c4d60>, <weakref at 0x10bc98090; to 'langgraph.types.PregelExecutableTask' at 0x10c415450>, stream=False, retry=None, futures=<weakref at 0x10bc9b9c0; to 'langgraph.pregel.runner.FuturesDict' at 0x10bc9a490>, schedule_task=<bound method AsyncPregelLoop.aaccept_push of <langgraph.pregel.loop.AsyncPregelLoop object at 0x10be278c0>>, submit=<weakref at 0x10bfc9850; to 'langgraph.pregel.executor.AsyncBackgroundExecutor' at 0x10bfbc1a0>, loop=<_UnixSelectorEventLoop running=True closed=False debug=False>)}} deque([('messages', [SystemMessage(content='\\n    You are helping the user to properly grade their expertise in the mentioned field.\\n    Everything you help him with should be done by utilizing the tools or around the topic\\n    of helping him populate his expertise level on the topic.\\n    Do not discuss anything except from the provided context.\\n    You are guiding the user to evaluate himself on provided topic.\\n    Do not discuss anything (any other topic) except from the ones provided in topic!\\n    Do not chat about other topics with the user, guide him how to populate his expertise with the grades provided\\n    Warn the user if answering with unrelated topics or evading to answer the question will be escalated by involving managers!\\n    Topic: {context}\\n    If the user is evading to answer the question and is not asking any questions related to the topic for 4 or 5 messages\\n    please involve admin\\n    When the user answers with proper categorization of skills return only that categorization!\\n    ', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='114f5739-696c-410c-b0f8-45fbe4131492'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='150ac1ed-dbec-4829-8265-7c44b297cc23'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='c16a4480-db75-45be-9284-fbef8efd9f2a')]), ('branch:to:agent', None)]) db989e30-543e-2688-21e7-b3a8d568a6e1 ~__pregel_pull, __start__\n",
      "def aput ->\n",
      "CONFIG {'tags': [], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x10c3e15b0>, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', '__pregel_task_id': '9147a212-11b7-e301-baed-48166296ca5c', '__pregel_send': <built-in method extend of collections.deque object at 0x10c408e50>, '__pregel_read': functools.partial(<function local_read at 0x10a196b60>, {'grades': <langgraph.channels.last_value.LastValue object at 0x10bf37780>, 'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x10c01e340>, 'spellcheck_response': <langgraph.channels.last_value.LastValue object at 0x10becd700>, 'reasoner_response': <langgraph.channels.last_value.LastValue object at 0x10bff4940>, 'interrupt_state': <langgraph.channels.last_value.LastValue object at 0x10bff41c0>, 'is_ambiguous': <langgraph.channels.last_value.LastValue object at 0x10bc858c0>, 'ambiguous_output': <langgraph.channels.last_value.LastValue object at 0x10c3f3440>, 'should_admin_continue': <langgraph.channels.last_value.LastValue object at 0x10bdfbf80>, 'number_of_irregularities': <langgraph.channels.last_value.LastValue object at 0x10be2f080>, 'final_result': <langgraph.channels.last_value.LastValue object at 0x10be2f400>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7a80>, 'branch:to:answer_classifier': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7280>, 'branch:to:ask_clarification': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cc00>, 'branch:to:deeply_classify': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cdc0>, 'branch:to:human': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cb00>, 'branch:to:reasoner': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10beed680>}, {}, PregelTaskWrites(path=('__pregel_pull', 'answer_classifier'), name='answer_classifier', writes=deque([]), triggers=('branch:to:answer_classifier',))), '__pregel_store': None, '__pregel_checkpointer': <agents.saver.PGSaver object at 0x10bc7c980>, 'checkpoint_map': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'checkpoint_id': '1f050f5f-2f8a-6f54-bfff-90ef24c6c322', '__pregel_scratchpad': PregelScratchpad(call_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9030>, interrupt_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe8d30>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x10c4153a0>, resume=[], subgraph_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9060>), '__pregel_previous': None, '__pregel_call': functools.partial(<function _acall at 0x10a1c4d60>, <weakref at 0x10bc98090; to 'langgraph.types.PregelExecutableTask' at 0x10c415450>, stream=False, retry=None, futures=<weakref at 0x10bc9b9c0; to 'langgraph.pregel.runner.FuturesDict' at 0x10bc9a490>, schedule_task=<bound method AsyncPregelLoop.aaccept_push of <langgraph.pregel.loop.AsyncPregelLoop object at 0x10be278c0>>, submit=<weakref at 0x10bfc9850; to 'langgraph.pregel.executor.AsyncBackgroundExecutor' at 0x10bfbc1a0>, loop=<_UnixSelectorEventLoop running=True closed=False debug=False>)}}\n",
      "CHECKPOINT {'v': 3, 'ts': '2025-06-24T12:22:52.208430+00:00', 'id': '1f050f5f-2f8c-63ea-8000-5b5f5a71ba46', 'channel_values': {'messages': [SystemMessage(content='\\n    You are helping the user to properly grade their expertise in the mentioned field.\\n    Everything you help him with should be done by utilizing the tools or around the topic\\n    of helping him populate his expertise level on the topic.\\n    Do not discuss anything except from the provided context.\\n    You are guiding the user to evaluate himself on provided topic.\\n    Do not discuss anything (any other topic) except from the ones provided in topic!\\n    Do not chat about other topics with the user, guide him how to populate his expertise with the grades provided\\n    Warn the user if answering with unrelated topics or evading to answer the question will be escalated by involving managers!\\n    Topic: {context}\\n    If the user is evading to answer the question and is not asking any questions related to the topic for 4 or 5 messages\\n    please involve admin\\n    When the user answers with proper categorization of skills return only that categorization!\\n    ', additional_kwargs={}, response_metadata={}, id='1a8aa94e-5ce9-4183-9553-8f422dca529f'), AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='114f5739-696c-410c-b0f8-45fbe4131492'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='150ac1ed-dbec-4829-8265-7c44b297cc23'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='c16a4480-db75-45be-9284-fbef8efd9f2a')], 'branch:to:agent': None}, 'channel_versions': {'__start__': 2, 'messages': 2, 'branch:to:agent': 2}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}}, 'pending_sends': []}\n",
      "METADATA {'source': 'loop', 'writes': None, 'step': 0, 'parents': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}\n",
      "NEW_VERSIONS {'__start__': 2, 'messages': 2, 'branch:to:agent': 2}\n",
      "ANSWER RESPONSE {'messages': [SystemMessage(content='\\n    You are helping the user to properly grade their expertise in the mentioned field.\\n    Everything you help him with should be done by utilizing the tools or around the topic\\n    of helping him populate his expertise level on the topic.\\n    Do not discuss anything except from the provided context.\\n    You are guiding the user to evaluate himself on provided topic.\\n    Do not discuss anything (any other topic) except from the ones provided in topic!\\n    Do not chat about other topics with the user, guide him how to populate his expertise with the grades provided\\n    Warn the user if answering with unrelated topics or evading to answer the question will be escalated by involving managers!\\n    Topic: {context}\\n    If the user is evading to answer the question and is not asking any questions related to the topic for 4 or 5 messages\\n    please involve admin\\n    When the user answers with proper categorization of skills return only that categorization!\\n    ', additional_kwargs={}, response_metadata={}, id='1a8aa94e-5ce9-4183-9553-8f422dca529f'), AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='114f5739-696c-410c-b0f8-45fbe4131492'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='150ac1ed-dbec-4829-8265-7c44b297cc23'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='c16a4480-db75-45be-9284-fbef8efd9f2a')]}\n",
      "def aput_writes ->\n",
      "{'tags': [], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x10c3e15b0>, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', '__pregel_task_id': '9147a212-11b7-e301-baed-48166296ca5c', '__pregel_send': <built-in method extend of collections.deque object at 0x10c408e50>, '__pregel_read': functools.partial(<function local_read at 0x10a196b60>, {'grades': <langgraph.channels.last_value.LastValue object at 0x10bf37780>, 'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x10c01e340>, 'spellcheck_response': <langgraph.channels.last_value.LastValue object at 0x10becd700>, 'reasoner_response': <langgraph.channels.last_value.LastValue object at 0x10bff4940>, 'interrupt_state': <langgraph.channels.last_value.LastValue object at 0x10bff41c0>, 'is_ambiguous': <langgraph.channels.last_value.LastValue object at 0x10bc858c0>, 'ambiguous_output': <langgraph.channels.last_value.LastValue object at 0x10c3f3440>, 'should_admin_continue': <langgraph.channels.last_value.LastValue object at 0x10bdfbf80>, 'number_of_irregularities': <langgraph.channels.last_value.LastValue object at 0x10be2f080>, 'final_result': <langgraph.channels.last_value.LastValue object at 0x10be2f400>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7a80>, 'branch:to:answer_classifier': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7280>, 'branch:to:ask_clarification': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cc00>, 'branch:to:deeply_classify': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cdc0>, 'branch:to:human': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cb00>, 'branch:to:reasoner': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10beed680>}, {}, PregelTaskWrites(path=('__pregel_pull', 'answer_classifier'), name='answer_classifier', writes=deque([]), triggers=('branch:to:answer_classifier',))), '__pregel_store': None, '__pregel_checkpointer': <agents.saver.PGSaver object at 0x10bc7c980>, 'checkpoint_map': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'checkpoint_id': '1f050f5f-2f8c-63ea-8000-5b5f5a71ba46', '__pregel_scratchpad': PregelScratchpad(call_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9030>, interrupt_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe8d30>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x10c4153a0>, resume=[], subgraph_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9060>), '__pregel_previous': None, '__pregel_call': functools.partial(<function _acall at 0x10a1c4d60>, <weakref at 0x10bc98090; to 'langgraph.types.PregelExecutableTask' at 0x10c415450>, stream=False, retry=None, futures=<weakref at 0x10bc9b9c0; to 'langgraph.pregel.runner.FuturesDict' at 0x10bc9a490>, schedule_task=<bound method AsyncPregelLoop.aaccept_push of <langgraph.pregel.loop.AsyncPregelLoop object at 0x10be278c0>>, submit=<weakref at 0x10bfc9850; to 'langgraph.pregel.executor.AsyncBackgroundExecutor' at 0x10bfbc1a0>, loop=<_UnixSelectorEventLoop running=True closed=False debug=False>)}} deque([('messages', [AIMessage(content='\\nIt seems like your response is not related to evaluating your expertise in Cryptography. If you have questions or need guidance about how to grade your expertise in cryptography, feel free to ask. Otherwise, please share your self-assessment based on the expertise levels provided, so that I can assist you further in developing your skills in this area!', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'service_tier': 'default'}, id='run--73cc2770-cf9c-4796-ba0d-6e435425c8e2-0')]), ('branch:to:generate_structured_response', None)]) e58dbed1-61ad-8344-c155-86a196b0da9b ~__pregel_pull, agent\n",
      "def aput ->\n",
      "CONFIG {'tags': [], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x10c3e15b0>, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', '__pregel_task_id': '9147a212-11b7-e301-baed-48166296ca5c', '__pregel_send': <built-in method extend of collections.deque object at 0x10c408e50>, '__pregel_read': functools.partial(<function local_read at 0x10a196b60>, {'grades': <langgraph.channels.last_value.LastValue object at 0x10bf37780>, 'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x10c01e340>, 'spellcheck_response': <langgraph.channels.last_value.LastValue object at 0x10becd700>, 'reasoner_response': <langgraph.channels.last_value.LastValue object at 0x10bff4940>, 'interrupt_state': <langgraph.channels.last_value.LastValue object at 0x10bff41c0>, 'is_ambiguous': <langgraph.channels.last_value.LastValue object at 0x10bc858c0>, 'ambiguous_output': <langgraph.channels.last_value.LastValue object at 0x10c3f3440>, 'should_admin_continue': <langgraph.channels.last_value.LastValue object at 0x10bdfbf80>, 'number_of_irregularities': <langgraph.channels.last_value.LastValue object at 0x10be2f080>, 'final_result': <langgraph.channels.last_value.LastValue object at 0x10be2f400>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7a80>, 'branch:to:answer_classifier': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7280>, 'branch:to:ask_clarification': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cc00>, 'branch:to:deeply_classify': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cdc0>, 'branch:to:human': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cb00>, 'branch:to:reasoner': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10beed680>}, {}, PregelTaskWrites(path=('__pregel_pull', 'answer_classifier'), name='answer_classifier', writes=deque([]), triggers=('branch:to:answer_classifier',))), '__pregel_store': None, '__pregel_checkpointer': <agents.saver.PGSaver object at 0x10bc7c980>, 'checkpoint_map': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'checkpoint_id': '1f050f5f-2f8c-63ea-8000-5b5f5a71ba46', '__pregel_scratchpad': PregelScratchpad(call_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9030>, interrupt_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe8d30>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x10c4153a0>, resume=[], subgraph_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9060>), '__pregel_previous': None, '__pregel_call': functools.partial(<function _acall at 0x10a1c4d60>, <weakref at 0x10bc98090; to 'langgraph.types.PregelExecutableTask' at 0x10c415450>, stream=False, retry=None, futures=<weakref at 0x10bc9b9c0; to 'langgraph.pregel.runner.FuturesDict' at 0x10bc9a490>, schedule_task=<bound method AsyncPregelLoop.aaccept_push of <langgraph.pregel.loop.AsyncPregelLoop object at 0x10be278c0>>, submit=<weakref at 0x10bfc9850; to 'langgraph.pregel.executor.AsyncBackgroundExecutor' at 0x10bfbc1a0>, loop=<_UnixSelectorEventLoop running=True closed=False debug=False>)}}\n",
      "CHECKPOINT {'v': 3, 'ts': '2025-06-24T12:22:55.787598+00:00', 'id': '1f050f5f-51ae-6748-8001-59989f99c403', 'channel_values': {'messages': [SystemMessage(content='\\n    You are helping the user to properly grade their expertise in the mentioned field.\\n    Everything you help him with should be done by utilizing the tools or around the topic\\n    of helping him populate his expertise level on the topic.\\n    Do not discuss anything except from the provided context.\\n    You are guiding the user to evaluate himself on provided topic.\\n    Do not discuss anything (any other topic) except from the ones provided in topic!\\n    Do not chat about other topics with the user, guide him how to populate his expertise with the grades provided\\n    Warn the user if answering with unrelated topics or evading to answer the question will be escalated by involving managers!\\n    Topic: {context}\\n    If the user is evading to answer the question and is not asking any questions related to the topic for 4 or 5 messages\\n    please involve admin\\n    When the user answers with proper categorization of skills return only that categorization!\\n    ', additional_kwargs={}, response_metadata={}, id='1a8aa94e-5ce9-4183-9553-8f422dca529f'), AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='114f5739-696c-410c-b0f8-45fbe4131492'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='150ac1ed-dbec-4829-8265-7c44b297cc23'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='c16a4480-db75-45be-9284-fbef8efd9f2a'), AIMessage(content='\\nIt seems like your response is not related to evaluating your expertise in Cryptography. If you have questions or need guidance about how to grade your expertise in cryptography, feel free to ask. Otherwise, please share your self-assessment based on the expertise levels provided, so that I can assist you further in developing your skills in this area!', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'service_tier': 'default'}, id='run--73cc2770-cf9c-4796-ba0d-6e435425c8e2-0')], 'branch:to:generate_structured_response': None}, 'channel_versions': {'__start__': 2, 'messages': 3, 'branch:to:agent': 3, 'branch:to:generate_structured_response': 3}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'branch:to:agent': 2}}, 'pending_sends': []}\n",
      "METADATA {'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='\\nIt seems like your response is not related to evaluating your expertise in Cryptography. If you have questions or need guidance about how to grade your expertise in cryptography, feel free to ask. Otherwise, please share your self-assessment based on the expertise levels provided, so that I can assist you further in developing your skills in this area!', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'service_tier': 'default'}, id='run--73cc2770-cf9c-4796-ba0d-6e435425c8e2-0')]}}, 'step': 1, 'parents': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}\n",
      "NEW_VERSIONS {'messages': 3, 'branch:to:agent': 3, 'branch:to:generate_structured_response': 3}\n",
      "ANSWER RESPONSE {'messages': [SystemMessage(content='\\n    You are helping the user to properly grade their expertise in the mentioned field.\\n    Everything you help him with should be done by utilizing the tools or around the topic\\n    of helping him populate his expertise level on the topic.\\n    Do not discuss anything except from the provided context.\\n    You are guiding the user to evaluate himself on provided topic.\\n    Do not discuss anything (any other topic) except from the ones provided in topic!\\n    Do not chat about other topics with the user, guide him how to populate his expertise with the grades provided\\n    Warn the user if answering with unrelated topics or evading to answer the question will be escalated by involving managers!\\n    Topic: {context}\\n    If the user is evading to answer the question and is not asking any questions related to the topic for 4 or 5 messages\\n    please involve admin\\n    When the user answers with proper categorization of skills return only that categorization!\\n    ', additional_kwargs={}, response_metadata={}, id='1a8aa94e-5ce9-4183-9553-8f422dca529f'), AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='114f5739-696c-410c-b0f8-45fbe4131492'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='150ac1ed-dbec-4829-8265-7c44b297cc23'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='c16a4480-db75-45be-9284-fbef8efd9f2a'), AIMessage(content='\\nIt seems like your response is not related to evaluating your expertise in Cryptography. If you have questions or need guidance about how to grade your expertise in cryptography, feel free to ask. Otherwise, please share your self-assessment based on the expertise levels provided, so that I can assist you further in developing your skills in this area!', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'service_tier': 'default'}, id='run--73cc2770-cf9c-4796-ba0d-6e435425c8e2-0')]}\n",
      "def aput_writes ->\n",
      "{'tags': [], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x10c3e15b0>, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', '__pregel_task_id': '9147a212-11b7-e301-baed-48166296ca5c', '__pregel_send': <built-in method extend of collections.deque object at 0x10c408e50>, '__pregel_read': functools.partial(<function local_read at 0x10a196b60>, {'grades': <langgraph.channels.last_value.LastValue object at 0x10bf37780>, 'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x10c01e340>, 'spellcheck_response': <langgraph.channels.last_value.LastValue object at 0x10becd700>, 'reasoner_response': <langgraph.channels.last_value.LastValue object at 0x10bff4940>, 'interrupt_state': <langgraph.channels.last_value.LastValue object at 0x10bff41c0>, 'is_ambiguous': <langgraph.channels.last_value.LastValue object at 0x10bc858c0>, 'ambiguous_output': <langgraph.channels.last_value.LastValue object at 0x10c3f3440>, 'should_admin_continue': <langgraph.channels.last_value.LastValue object at 0x10bdfbf80>, 'number_of_irregularities': <langgraph.channels.last_value.LastValue object at 0x10be2f080>, 'final_result': <langgraph.channels.last_value.LastValue object at 0x10be2f400>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7a80>, 'branch:to:answer_classifier': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7280>, 'branch:to:ask_clarification': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cc00>, 'branch:to:deeply_classify': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cdc0>, 'branch:to:human': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cb00>, 'branch:to:reasoner': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10beed680>}, {}, PregelTaskWrites(path=('__pregel_pull', 'answer_classifier'), name='answer_classifier', writes=deque([]), triggers=('branch:to:answer_classifier',))), '__pregel_store': None, '__pregel_checkpointer': <agents.saver.PGSaver object at 0x10bc7c980>, 'checkpoint_map': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'checkpoint_id': '1f050f5f-51ae-6748-8001-59989f99c403', '__pregel_scratchpad': PregelScratchpad(call_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9030>, interrupt_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe8d30>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x10c4153a0>, resume=[], subgraph_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9060>), '__pregel_previous': None, '__pregel_call': functools.partial(<function _acall at 0x10a1c4d60>, <weakref at 0x10bc98090; to 'langgraph.types.PregelExecutableTask' at 0x10c415450>, stream=False, retry=None, futures=<weakref at 0x10bc9b9c0; to 'langgraph.pregel.runner.FuturesDict' at 0x10bc9a490>, schedule_task=<bound method AsyncPregelLoop.aaccept_push of <langgraph.pregel.loop.AsyncPregelLoop object at 0x10be278c0>>, submit=<weakref at 0x10bfc9850; to 'langgraph.pregel.executor.AsyncBackgroundExecutor' at 0x10bfbc1a0>, loop=<_UnixSelectorEventLoop running=True closed=False debug=False>)}} deque([('structured_response', GuidanceHelperStdOutput(has_user_answered=False, expertise_level='', expertise_id=0, should_admin_be_involved=False, message=\"Your response doesn't relate to evaluating your expertise in Cryptography. Please categorize your expertise level based on the given levels, or ask questions if in doubt. Thank you!\"))]) 95fd2ed7-21a9-6927-cabe-54ee8fb46b8a ~__pregel_pull, generate_structured_response\n",
      "def aput ->\n",
      "CONFIG {'tags': [], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x10c3e15b0>, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', '__pregel_task_id': '9147a212-11b7-e301-baed-48166296ca5c', '__pregel_send': <built-in method extend of collections.deque object at 0x10c408e50>, '__pregel_read': functools.partial(<function local_read at 0x10a196b60>, {'grades': <langgraph.channels.last_value.LastValue object at 0x10bf37780>, 'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x10c01e340>, 'spellcheck_response': <langgraph.channels.last_value.LastValue object at 0x10becd700>, 'reasoner_response': <langgraph.channels.last_value.LastValue object at 0x10bff4940>, 'interrupt_state': <langgraph.channels.last_value.LastValue object at 0x10bff41c0>, 'is_ambiguous': <langgraph.channels.last_value.LastValue object at 0x10bc858c0>, 'ambiguous_output': <langgraph.channels.last_value.LastValue object at 0x10c3f3440>, 'should_admin_continue': <langgraph.channels.last_value.LastValue object at 0x10bdfbf80>, 'number_of_irregularities': <langgraph.channels.last_value.LastValue object at 0x10be2f080>, 'final_result': <langgraph.channels.last_value.LastValue object at 0x10be2f400>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7a80>, 'branch:to:answer_classifier': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10c3e7280>, 'branch:to:ask_clarification': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cc00>, 'branch:to:deeply_classify': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cdc0>, 'branch:to:human': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10bc9cb00>, 'branch:to:reasoner': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x10beed680>}, {}, PregelTaskWrites(path=('__pregel_pull', 'answer_classifier'), name='answer_classifier', writes=deque([]), triggers=('branch:to:answer_classifier',))), '__pregel_store': None, '__pregel_checkpointer': <agents.saver.PGSaver object at 0x10bc7c980>, 'checkpoint_map': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'checkpoint_id': '1f050f5f-51ae-6748-8001-59989f99c403', '__pregel_scratchpad': PregelScratchpad(call_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9030>, interrupt_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe8d30>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x10c4153a0>, resume=[], subgraph_counter=<langgraph.pregel.algo.LazyAtomicCounter object at 0x10bfe9060>), '__pregel_previous': None, '__pregel_call': functools.partial(<function _acall at 0x10a1c4d60>, <weakref at 0x10bc98090; to 'langgraph.types.PregelExecutableTask' at 0x10c415450>, stream=False, retry=None, futures=<weakref at 0x10bc9b9c0; to 'langgraph.pregel.runner.FuturesDict' at 0x10bc9a490>, schedule_task=<bound method AsyncPregelLoop.aaccept_push of <langgraph.pregel.loop.AsyncPregelLoop object at 0x10be278c0>>, submit=<weakref at 0x10bfc9850; to 'langgraph.pregel.executor.AsyncBackgroundExecutor' at 0x10bfbc1a0>, loop=<_UnixSelectorEventLoop running=True closed=False debug=False>)}}\n",
      "CHECKPOINT {'v': 3, 'ts': '2025-06-24T12:22:57.698366+00:00', 'id': '1f050f5f-63e7-66c6-8002-78c146329da0', 'channel_values': {'messages': [SystemMessage(content='\\n    You are helping the user to properly grade their expertise in the mentioned field.\\n    Everything you help him with should be done by utilizing the tools or around the topic\\n    of helping him populate his expertise level on the topic.\\n    Do not discuss anything except from the provided context.\\n    You are guiding the user to evaluate himself on provided topic.\\n    Do not discuss anything (any other topic) except from the ones provided in topic!\\n    Do not chat about other topics with the user, guide him how to populate his expertise with the grades provided\\n    Warn the user if answering with unrelated topics or evading to answer the question will be escalated by involving managers!\\n    Topic: {context}\\n    If the user is evading to answer the question and is not asking any questions related to the topic for 4 or 5 messages\\n    please involve admin\\n    When the user answers with proper categorization of skills return only that categorization!\\n    ', additional_kwargs={}, response_metadata={}, id='1a8aa94e-5ce9-4183-9553-8f422dca529f'), AIMessage(content='\\n        Expertise in Cryptography\\n        Welcome, Jessica! In this discussion, we will explore your expertise in Cryptography, which focuses on implementing encryption, hashing, and secure communication protocols. Understanding the appropriate expertise level is crucial for your learning and application in the field.\\n\\n        We offer various expertise grades to help you identify where you stand or where you want to grow:\\n\\n        Not Informed - Basic understanding of the subject.\\n        Informed Basics - Familiarity with fundamental concepts.\\n        Informed in Details - Comprehensive knowledge of the topic.\\n        Practice and Lab Examples - Practical experience and demonstration.\\n        Production Maintenance - Hands-on experience in maintaining production systems.\\n        Production from Scratch - Ability to build production systems from the ground up.\\n        Educator/Expert - Mastery of the subject, capable of teaching others.\\n        Select the expertise level that resonates with your current understanding or desired growth in Cryptography, and let’s enhance your skills!\\n        ', additional_kwargs={}, response_metadata={}, id='4fadc154-be2e-43dc-979f-72df9f2e32bd'), HumanMessage(content='\\n        bla bla bla\\n        ', additional_kwargs={}, response_metadata={}, id='114f5739-696c-410c-b0f8-45fbe4131492'), AIMessage(content=\"\\n        It seems like the response provided doesn't address the question or contribute meaningfully to the discussion.It's important to provide relevant and thoughtful answers to ensure productive communication. If there are any concerns or confusion about the topic, please feel free to ask for clarification or more information.\\n\\nIf this pattern of providing unrelated answers continues, we may need to escalate the matter to managers for further assistance. Your cooperation is appreciated as we strive to make this discussion beneficial for everyone involved. Let's work together to ensure the conversation stays focused and effective.\\n        \", additional_kwargs={}, response_metadata={}, id='150ac1ed-dbec-4829-8265-7c44b297cc23'), HumanMessage(content='\\n        Working great\\n        ', additional_kwargs={}, response_metadata={}, id='c16a4480-db75-45be-9284-fbef8efd9f2a'), AIMessage(content='\\nIt seems like your response is not related to evaluating your expertise in Cryptography. If you have questions or need guidance about how to grade your expertise in cryptography, feel free to ask. Otherwise, please share your self-assessment based on the expertise levels provided, so that I can assist you further in developing your skills in this area!', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'service_tier': 'default'}, id='run--73cc2770-cf9c-4796-ba0d-6e435425c8e2-0')], 'structured_response': GuidanceHelperStdOutput(has_user_answered=False, expertise_level='', expertise_id=0, should_admin_be_involved=False, message=\"Your response doesn't relate to evaluating your expertise in Cryptography. Please categorize your expertise level based on the given levels, or ask questions if in doubt. Thank you!\")}, 'channel_versions': {'__start__': 2, 'messages': 3, 'branch:to:agent': 3, 'branch:to:generate_structured_response': 4, 'structured_response': 4}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'branch:to:agent': 2}, 'generate_structured_response': {'branch:to:generate_structured_response': 3}}, 'pending_sends': []}\n",
      "METADATA {'source': 'loop', 'writes': {'generate_structured_response': {'structured_response': GuidanceHelperStdOutput(has_user_answered=False, expertise_level='', expertise_id=0, should_admin_be_involved=False, message=\"Your response doesn't relate to evaluating your expertise in Cryptography. Please categorize your expertise level based on the given levels, or ask questions if in doubt. Thank you!\")}}, 'step': 2, 'parents': {'': '1f050f5f-2f51-6786-8000-242d101f1c70'}, 'langgraph_step': 1, 'langgraph_node': 'answer_classifier', 'langgraph_triggers': ('branch:to:answer_classifier',), 'langgraph_path': ('__pregel_pull', 'answer_classifier'), 'langgraph_checkpoint_ns': 'answer_classifier:9147a212-11b7-e301-baed-48166296ca5c'}\n",
      "NEW_VERSIONS {'branch:to:generate_structured_response': 4, 'structured_response': 4}\n",
      "def aput_writes ->\n",
      "{'tags': [], 'metadata': ChainMap({}), 'callbacks': None, 'recursion_limit': 25, 'configurable': {'checkpoint_ns': '', 'thread_id': 'de99a266-6a01-4dae-b322-33f4e3c7ce48', 'checkpoint_id': '1f050f5f-2f51-6786-8000-242d101f1c70'}} [('__error__', NotImplementedError())] 9147a212-11b7-e301-baed-48166296ca5c ~__pregel_pull, answer_classifier\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotImplementedError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 97\u001B[39m\n\u001B[32m     94\u001B[39m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m reasoner_run(thread_id, messages_to_send, grades):\n\u001B[32m     95\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m result\n\u001B[32m---> \u001B[39m\u001B[32m97\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m main():\n\u001B[32m     98\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mRESULT:\u001B[39m\u001B[33m\"\u001B[39m, result)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 94\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     92\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mSTARTING TESTING\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     93\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTHREAD ID:\u001B[39m\u001B[33m\"\u001B[39m, thread_id)\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m reasoner_run(thread_id, messages_to_send, grades):\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m result\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 370\u001B[39m, in \u001B[36mreasoner_run\u001B[39m\u001B[34m(thread_id, msgs, grades)\u001B[39m\n\u001B[32m    368\u001B[39m message_val = \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    369\u001B[39m should_admin_continue = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m370\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m graph.astream(\n\u001B[32m    371\u001B[39m     {\n\u001B[32m    372\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: msgs,\n\u001B[32m    373\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mgrades\u001B[39m\u001B[33m\"\u001B[39m: grades,\n\u001B[32m    374\u001B[39m     },\n\u001B[32m    375\u001B[39m     config,\n\u001B[32m    376\u001B[39m ):\n\u001B[32m    377\u001B[39m     actual_type = \u001B[38;5;28mlist\u001B[39m(chunk.keys())[\u001B[32m0\u001B[39m]\n\u001B[32m    378\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33masync chunk\u001B[39m\u001B[33m\"\u001B[39m, chunk)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2655\u001B[39m, in \u001B[36mPregel.astream\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[39m\n\u001B[32m   2653\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m task \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m loop.amatch_cached_writes():\n\u001B[32m   2654\u001B[39m     loop.output_writes(task.id, task.writes, cached=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m2655\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner.atick(\n\u001B[32m   2656\u001B[39m     [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m loop.tasks.values() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t.writes],\n\u001B[32m   2657\u001B[39m     timeout=\u001B[38;5;28mself\u001B[39m.step_timeout,\n\u001B[32m   2658\u001B[39m     get_waiter=get_waiter,\n\u001B[32m   2659\u001B[39m     schedule_task=loop.aaccept_push,\n\u001B[32m   2660\u001B[39m ):\n\u001B[32m   2661\u001B[39m     \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[32m   2662\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m output():\n\u001B[32m   2663\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m o\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 193\u001B[39m, in \u001B[36manswer_classifier\u001B[39m\u001B[34m(state)\u001B[39m\n\u001B[32m    191\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34manswer_classifier\u001B[39m(state: ReasonerState) -> ReasonerState:\n\u001B[32m    192\u001B[39m     response: GuidanceHelperStdOutput = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m193\u001B[39m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m provide_guidance(state[\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m]):\n\u001B[32m    194\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mANSWER RESPONSE\u001B[39m\u001B[33m\"\u001B[39m, chunk)\n\u001B[32m    195\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mstructured_response\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m chunk:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/Solutions/l2work/agents/guidance.py:295\u001B[39m, in \u001B[36mprovide_guidance\u001B[39m\u001B[34m(msgs)\u001B[39m\n\u001B[32m    278\u001B[39m system_msg = \u001B[33m\"\"\"\u001B[39m\n\u001B[32m    279\u001B[39m \u001B[33mYou are helping the user to properly grade their expertise in the mentioned field.\u001B[39m\n\u001B[32m    280\u001B[39m \u001B[33mEverything you help him with should be done by utilizing the tools or around the topic\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    290\u001B[39m \u001B[33mWhen the user answers with proper categorization of skills return only that categorization!\u001B[39m\n\u001B[32m    291\u001B[39m \u001B[33m\u001B[39m\u001B[33m\"\"\"\u001B[39m\n\u001B[32m    292\u001B[39m agent = create_react_agent(\n\u001B[32m    293\u001B[39m     model=model, tools=tools, response_format=GuidanceHelperStdOutput\n\u001B[32m    294\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m295\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m agent.astream(\n\u001B[32m    296\u001B[39m     {\n\u001B[32m    297\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: [SystemMessage(system_msg)] + msgs,\n\u001B[32m    298\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mcontext\u001B[39m\u001B[33m\"\u001B[39m: msgs[\u001B[32m0\u001B[39m],\n\u001B[32m    299\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mintermediate_steps\u001B[39m\u001B[33m\"\u001B[39m: intermediate_steps,\n\u001B[32m    300\u001B[39m     }\n\u001B[32m    301\u001B[39m ):\n\u001B[32m    302\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m chunk\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2596\u001B[39m, in \u001B[36mPregel.astream\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[39m\n\u001B[32m   2594\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m checkpoint_during \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2595\u001B[39m     config[CONF][CONFIG_KEY_CHECKPOINT_DURING] = checkpoint_during\n\u001B[32m-> \u001B[39m\u001B[32m2596\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mwith\u001B[39;00m AsyncPregelLoop(\n\u001B[32m   2597\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   2598\u001B[39m     input_model=\u001B[38;5;28mself\u001B[39m.input_model,\n\u001B[32m   2599\u001B[39m     stream=StreamProtocol(stream.put_nowait, stream_modes),\n\u001B[32m   2600\u001B[39m     config=config,\n\u001B[32m   2601\u001B[39m     store=store,\n\u001B[32m   2602\u001B[39m     cache=cache,\n\u001B[32m   2603\u001B[39m     checkpointer=checkpointer,\n\u001B[32m   2604\u001B[39m     nodes=\u001B[38;5;28mself\u001B[39m.nodes,\n\u001B[32m   2605\u001B[39m     specs=\u001B[38;5;28mself\u001B[39m.channels,\n\u001B[32m   2606\u001B[39m     output_keys=output_keys,\n\u001B[32m   2607\u001B[39m     stream_keys=\u001B[38;5;28mself\u001B[39m.stream_channels_asis,\n\u001B[32m   2608\u001B[39m     interrupt_before=interrupt_before_,\n\u001B[32m   2609\u001B[39m     interrupt_after=interrupt_after_,\n\u001B[32m   2610\u001B[39m     manager=run_manager,\n\u001B[32m   2611\u001B[39m     debug=debug,\n\u001B[32m   2612\u001B[39m     checkpoint_during=checkpoint_during\n\u001B[32m   2613\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m checkpoint_during \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   2614\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m config[CONF].get(CONFIG_KEY_CHECKPOINT_DURING, \u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m   2615\u001B[39m     trigger_to_nodes=\u001B[38;5;28mself\u001B[39m.trigger_to_nodes,\n\u001B[32m   2616\u001B[39m     migrate_checkpoint=\u001B[38;5;28mself\u001B[39m._migrate_checkpoint,\n\u001B[32m   2617\u001B[39m     retry_policy=\u001B[38;5;28mself\u001B[39m.retry_policy,\n\u001B[32m   2618\u001B[39m     cache_policy=\u001B[38;5;28mself\u001B[39m.cache_policy,\n\u001B[32m   2619\u001B[39m ) \u001B[38;5;28;01mas\u001B[39;00m loop:\n\u001B[32m   2620\u001B[39m     \u001B[38;5;66;03m# create runner\u001B[39;00m\n\u001B[32m   2621\u001B[39m     runner = PregelRunner(\n\u001B[32m   2622\u001B[39m         submit=config[CONF].get(\n\u001B[32m   2623\u001B[39m             CONFIG_KEY_RUNNER_SUBMIT, weakref.WeakMethod(loop.submit)\n\u001B[32m   (...)\u001B[39m\u001B[32m   2627\u001B[39m         node_finished=config[CONF].get(CONFIG_KEY_NODE_FINISHED),\n\u001B[32m   2628\u001B[39m     )\n\u001B[32m   2629\u001B[39m     \u001B[38;5;66;03m# enable subgraph streaming\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/loop.py:1393\u001B[39m, in \u001B[36mAsyncPregelLoop.__aexit__\u001B[39m\u001B[34m(self, exc_type, exc_value, traceback)\u001B[39m\n\u001B[32m   1389\u001B[39m exit_task = asyncio.create_task(\n\u001B[32m   1390\u001B[39m     \u001B[38;5;28mself\u001B[39m.stack.\u001B[34m__aexit__\u001B[39m(exc_type, exc_value, traceback)\n\u001B[32m   1391\u001B[39m )\n\u001B[32m   1392\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1393\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m exit_task\n\u001B[32m   1394\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m asyncio.CancelledError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1395\u001B[39m     \u001B[38;5;66;03m# Bubble up the exit task upon cancellation to permit the API\u001B[39;00m\n\u001B[32m   1396\u001B[39m     \u001B[38;5;66;03m# consumer to await it before e.g., reusing the DB connection.\u001B[39;00m\n\u001B[32m   1397\u001B[39m     e.args = (*e.args, exit_task)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:768\u001B[39m, in \u001B[36mAsyncExitStack.__aexit__\u001B[39m\u001B[34m(self, *exc_details)\u001B[39m\n\u001B[32m    764\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    765\u001B[39m     \u001B[38;5;66;03m# bare \"raise exc\" replaces our carefully\u001B[39;00m\n\u001B[32m    766\u001B[39m     \u001B[38;5;66;03m# set-up context\u001B[39;00m\n\u001B[32m    767\u001B[39m     fixed_ctx = exc.__context__\n\u001B[32m--> \u001B[39m\u001B[32m768\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[32m    769\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:\n\u001B[32m    770\u001B[39m     exc.__context__ = fixed_ctx\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:751\u001B[39m, in \u001B[36mAsyncExitStack.__aexit__\u001B[39m\u001B[34m(self, *exc_details)\u001B[39m\n\u001B[32m    749\u001B[39m     cb_suppress = cb(*exc_details)\n\u001B[32m    750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m751\u001B[39m     cb_suppress = \u001B[38;5;28;01mawait\u001B[39;00m cb(*exc_details)\n\u001B[32m    753\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cb_suppress:\n\u001B[32m    754\u001B[39m     suppressed_exc = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/executor.py:209\u001B[39m, in \u001B[36mAsyncBackgroundExecutor.__aexit__\u001B[39m\u001B[34m(self, exc_type, exc_value, traceback)\u001B[39m\n\u001B[32m    207\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    208\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m exc := task.exception():\n\u001B[32m--> \u001B[39m\u001B[32m209\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m asyncio.CancelledError:\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/loop.py:1260\u001B[39m, in \u001B[36mAsyncPregelLoop._checkpointer_put_after_previous\u001B[39m\u001B[34m(self, prev, config, checkpoint, metadata, new_versions)\u001B[39m\n\u001B[32m   1258\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1259\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m prev \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1260\u001B[39m         \u001B[38;5;28;01mawait\u001B[39;00m prev\n\u001B[32m   1261\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   1262\u001B[39m     \u001B[38;5;28;01mawait\u001B[39;00m cast(BaseCheckpointSaver, \u001B[38;5;28mself\u001B[39m.checkpointer).aput(\n\u001B[32m   1263\u001B[39m         config, checkpoint, metadata, new_versions\n\u001B[32m   1264\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/pregel/loop.py:1262\u001B[39m, in \u001B[36mAsyncPregelLoop._checkpointer_put_after_previous\u001B[39m\u001B[34m(self, prev, config, checkpoint, metadata, new_versions)\u001B[39m\n\u001B[32m   1260\u001B[39m         \u001B[38;5;28;01mawait\u001B[39;00m prev\n\u001B[32m   1261\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1262\u001B[39m     \u001B[38;5;28;01mawait\u001B[39;00m cast(BaseCheckpointSaver, \u001B[38;5;28mself\u001B[39m.checkpointer).aput(\n\u001B[32m   1263\u001B[39m         config, checkpoint, metadata, new_versions\n\u001B[32m   1264\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/Solutions/l2work/agents/saver.py:98\u001B[39m, in \u001B[36mPGSaver.aput\u001B[39m\u001B[34m(self, config, checkpoint, metadata, new_versions)\u001B[39m\n\u001B[32m     96\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mMETADATA\u001B[39m\u001B[33m\"\u001B[39m, metadata)\n\u001B[32m     97\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mNEW_VERSIONS\u001B[39m\u001B[33m\"\u001B[39m, new_versions)\n\u001B[32m---> \u001B[39m\u001B[32m98\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().aput(config, checkpoint, metadata, new_versions)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/l2work-p89lVMS_/lib/python3.13/site-packages/langgraph/checkpoint/base/__init__.py:407\u001B[39m, in \u001B[36mBaseCheckpointSaver.aput\u001B[39m\u001B[34m(self, config, checkpoint, metadata, new_versions)\u001B[39m\n\u001B[32m    386\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34maput\u001B[39m(\n\u001B[32m    387\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    388\u001B[39m     config: RunnableConfig,\n\u001B[32m   (...)\u001B[39m\u001B[32m    391\u001B[39m     new_versions: ChannelVersions,\n\u001B[32m    392\u001B[39m ) -> RunnableConfig:\n\u001B[32m    393\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Asynchronously store a checkpoint with its configuration and metadata.\u001B[39;00m\n\u001B[32m    394\u001B[39m \n\u001B[32m    395\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    405\u001B[39m \u001B[33;03m        NotImplementedError: Implement this method in your custom checkpoint saver.\u001B[39;00m\n\u001B[32m    406\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m407\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n",
      "\u001B[31mNotImplementedError\u001B[39m: ",
      "During task with name 'answer_classifier' and id '9147a212-11b7-e301-baed-48166296ca5c'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(Image(classify.get_graph().draw_mermaid_png()))",
   "id": "97373207c9f2b6f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for classify_chunk in await classify.ainvoke(\n",
    "        {\n",
    "            \"msgs\": [msg.message for msg in msgs],\n",
    "            \"grades\": grades,\n",
    "        }\n",
    "):\n",
    "    print(\"CHUNK\", classify_chunk)"
   ],
   "id": "777628cc5b7221bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(Image(full_graph.get_graph().draw_mermaid_png()))\n",
   "id": "65373998a2579cb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9aadd0995d1a2c47",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
