{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-07T11:31:20.210285Z",
     "start_time": "2025-07-07T11:31:20.205990Z"
    }
   },
   "source": [
    "import os\n",
    "from typing import (\n",
    "    List,\n",
    "    Any,\n",
    "    AsyncGenerator,\n",
    "    Coroutine,\n",
    "    Tuple,\n",
    "    Optional,\n",
    "    TypedDict,\n",
    "    Annotated,\n",
    "    Literal,\n",
    "    Union,\n",
    ")\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import AIMessage, SystemMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.tools import StructuredTool, render_text_description\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from sqlalchemy import Row, RowMapping\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from agents.consts import (\n",
    "    GUIDANCE_PROMPT,\n",
    "    DISCREPANCY_TEMPLATE,\n",
    "    SUPERVISOR_TEMPLATE,\n",
    "    FEEDBACK_TEMPLATE,\n",
    "    GUIDANCE_TEMPLATE,\n",
    ")\n",
    "from agents.llm_callback import CustomLlmTrackerCallback\n",
    "from db.db import get_session\n",
    "from db.models import Grade, UserSkills, User, Skill\n",
    "from service.service import BaseService\n",
    "from utils.common import convert_agent_msg_to_llm_message"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T11:31:20.640396Z",
     "start_time": "2025-07-07T11:31:20.634314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "search = TavilySearchResults()\n",
    "\n",
    "LITE_LLM_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LITE_LLM_URL = os.getenv(\"OPENAI_BASE_URL\")\n",
    "LITE_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "\n",
    "custom_callback = CustomLlmTrackerCallback(\"guidance\")"
   ],
   "id": "e3c0cab83c35bdcd",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T11:31:21.017504Z",
     "start_time": "2025-07-07T11:31:21.010139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from agents.dto import AgentMessage, ChatMessage\n",
    "import operator\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "\n",
    "async def find_current_grade_for_user_and_skill(\n",
    "    user_id: int, skill_id: int\n",
    ") -> UserSkills:\n",
    "    \"\"\"\n",
    "    Utilize to find current expertise and grading level with user id and skill_id\n",
    "    :param user_id: users id\n",
    "    :param skill_id: skill id\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    async for session in get_session():\n",
    "        user_skill_service: BaseService[UserSkills, int, Any, Any] = BaseService(\n",
    "            UserSkills, session\n",
    "        )\n",
    "        filters = {\n",
    "            \"user_id\": user_id,\n",
    "            \"skill_id\": skill_id,\n",
    "        }\n",
    "        user_skill = await user_skill_service.list_all(filters=filters)\n",
    "        if len(user_skill) == 0:\n",
    "            raise Exception(f\"No user_skills found for user_id {user_id}\")\n",
    "        single_user_skill = user_skill[0]\n",
    "        await single_user_skill.awaitable_attrs.user\n",
    "        await single_user_skill.awaitable_attrs.skill\n",
    "        await single_user_skill.awaitable_attrs.grade\n",
    "        return single_user_skill\n",
    "\n",
    "\n",
    "class DiscrepancyValues(BaseModel):\n",
    "    grade_id: int\n",
    "    skill_id: int\n",
    "    user_id: int\n",
    "\n",
    "\n",
    "class GuidanceValue(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "class SupervisorState(TypedDict):\n",
    "    discrepancy: DiscrepancyValues\n",
    "    guidance: GuidanceValue\n",
    "    next_steps: Annotated[List[str], operator.add]\n",
    "    messages: Annotated[List[AgentMessage], operator.add]\n",
    "    chat_messages: Annotated[List[ChatMessage], operator.add]\n",
    "\n",
    "\n",
    "async def discrepancy_agent(state: SupervisorState) -> SupervisorState:\n",
    "    \"\"\"\n",
    "    Discrepancy agent that resolves the discrepancies and explains\n",
    "    the differences between the grades from saved and now provided stated\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    discrepancy_callback = CustomLlmTrackerCallback(\"discrepancy_agent\")\n",
    "    tools = [\n",
    "        StructuredTool.from_function(\n",
    "            function=find_current_grade_for_user_and_skill,\n",
    "            coroutine=find_current_grade_for_user_and_skill,\n",
    "        ),\n",
    "        StructuredTool.from_function(\n",
    "            function=get_grades_or_expertise,\n",
    "            coroutine=get_grades_or_expertise,\n",
    "        ),\n",
    "    ]\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=300,\n",
    "        model=LITE_MODEL,\n",
    "        api_key=LITE_LLM_API_KEY,\n",
    "        base_url=LITE_LLM_URL,\n",
    "        streaming=True,\n",
    "        verbose=True,\n",
    "        callbacks=[discrepancy_callback],\n",
    "    )\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(DISCREPANCY_TEMPLATE)\n",
    "    prompt = await prompt_template.ainvoke(\n",
    "        input={\n",
    "            \"user_id\": state[\"discrepancy\"].user_id,\n",
    "            \"skill_id\": state[\"discrepancy\"].skill_id,\n",
    "            \"current_grade\": state[\"discrepancy\"].grade_id,\n",
    "        }\n",
    "    )\n",
    "    print(f\"\\n\\nDISCREPANCY AGAIN PROMPT\\n {prompt}\")\n",
    "    agent = create_react_agent(model=model, tools=tools)\n",
    "    response = await agent.ainvoke(prompt)\n",
    "    print(f\"\\n\\nDISCREPANCY AGAIN RESPONSE\\n {response}\")\n",
    "    msg = []\n",
    "    if \"messages\" in response and len(response[\"messages\"]) > 0:\n",
    "        response_msgs = response[\"messages\"][-1]\n",
    "        msg = [\n",
    "            AgentMessage(\n",
    "                message=response_msgs,\n",
    "                role=\"discrepancy\",\n",
    "            )\n",
    "        ]\n",
    "    return {\n",
    "        \"discrepancy\": state[\"discrepancy\"],\n",
    "        \"guidance\": state[\"guidance\"],\n",
    "        \"next_steps\": state[\"next_steps\"],\n",
    "        \"messages\": msg,\n",
    "        \"chat_messages\": state[\"chat_messages\"],\n",
    "    }"
   ],
   "id": "775f0f21259cefd7",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T11:31:21.433191Z",
     "start_time": "2025-07-07T11:31:21.421891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "\n",
    "async def supervisor_agent(state: SupervisorState) -> SupervisorState:\n",
    "    prompt_template = ChatPromptTemplate.from_template(SUPERVISOR_TEMPLATE)\n",
    "    msgs = []\n",
    "    for msg in state[\"chat_messages\"]:\n",
    "        if msg[\"role\"] == \"human\":\n",
    "            answer = f\"Answer: {msg[\"message\"]}\"\n",
    "            msgs.append(answer)\n",
    "        elif msg[\"role\"] == \"ai\":\n",
    "            question = f\"Question: {msg[\"message\"]}\"\n",
    "            msgs.append(question)\n",
    "    prompt_msgs = \"\\n\".join(msgs)\n",
    "    scratchpad_msgs = [m.message.content for m in state[\"messages\"]]\n",
    "    scratchpad_msgs_str = \"\\n\".join(scratchpad_msgs)\n",
    "    prompt = await prompt_template.ainvoke(\n",
    "        {\"discussion\": prompt_msgs, \"agent_scratchpad\": scratchpad_msgs_str}\n",
    "    )\n",
    "    print(f\"\\n\\nSUPERVISOR AGENT PROMPT\\n {prompt}\")\n",
    "\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=300,\n",
    "        model=LITE_MODEL,\n",
    "        api_key=LITE_LLM_API_KEY,\n",
    "        base_url=LITE_LLM_URL,\n",
    "        streaming=True,\n",
    "        verbose=True,\n",
    "        stop=[\"\\nObserve:\"],\n",
    "    )\n",
    "    response = await model.ainvoke(prompt)\n",
    "    print(f\"\\n\\nSUPERVISOR AGENT RESPONSE\\n {response}\")\n",
    "    content = response.content\n",
    "    next_steps = []\n",
    "    match = re.search(r\"\\nCall: (discrepancy|guidance|feedback|grading)\", content)\n",
    "\n",
    "    if match:\n",
    "        print(\"\\n\\n\\nIS MATCHING THIS\\n\\n\\n\")\n",
    "        for val in match.groups():\n",
    "            next_steps.append(val)\n",
    "    else:\n",
    "        next_steps.append(\"finish\")\n",
    "        print(\"\\n\\n\\nFINISHHHHHHH\\n\\n\\n\")\n",
    "\n",
    "    msg = AgentMessage(\n",
    "        message=response,\n",
    "        role=\"supervisor\",\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"discrepancy\": state[\"discrepancy\"],\n",
    "        \"guidance\": state[\"guidance\"],\n",
    "        \"next_steps\": next_steps,\n",
    "        \"messages\": [msg],\n",
    "        \"chat_messages\": state[\"chat_messages\"],\n",
    "    }\n",
    "\n",
    "\n",
    "async def grading_agent(state: SupervisorState) -> SupervisorState:\n",
    "    system_msg = \"\"\"\n",
    "        Based on the provided discussion your job is to confirm the level of expertise of the user!\n",
    "        If you are not sure that the grade or expertise is clearly recognizable please let the the user know\n",
    "        If you're certain state explicitly which expertise is correct for the user!\n",
    "\n",
    "        Discussion:\n",
    "        {discussion}\n",
    "        \"\"\"\n",
    "    prompt_template = ChatPromptTemplate.from_template(system_msg)\n",
    "    msgs = []\n",
    "    for msg in state[\"chat_messages\"]:\n",
    "        if msg[\"role\"] == \"human\":\n",
    "            answer = f\"Answer: {msg[\"message\"]}\"\n",
    "            msgs.append(answer)\n",
    "        elif msg[\"role\"] == \"ai\":\n",
    "            question = f\"Question: {msg[\"message\"]}\"\n",
    "            msgs.append(question)\n",
    "\n",
    "    prompt = await prompt_template.ainvoke(input={\"discussion\": \"\\n\".join(msgs)})\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=300,\n",
    "        model=LITE_MODEL,\n",
    "        api_key=LITE_LLM_API_KEY,\n",
    "        base_url=LITE_LLM_URL,\n",
    "        streaming=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    response = await model.ainvoke(prompt)\n",
    "    print(f\"\\n\\nGRADING AGENT RESPONSE\\n {response}\")\n",
    "    msg = AgentMessage(message=response, role=\"grade\")\n",
    "    return {\n",
    "        \"discrepancy\": state[\"discrepancy\"],\n",
    "        \"guidance\": state[\"guidance\"],\n",
    "        \"next_steps\": state[\"next_steps\"],\n",
    "        \"messages\": [msg],\n",
    "        \"chat_messages\": state[\"chat_messages\"],\n",
    "    }\n",
    "\n",
    "\n",
    "async def evasion_detector_agent(state: SupervisorState) -> SupervisorState:\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        From provided discussion, check whether the user is evading to answer a provided question?\n",
    "\n",
    "        Discussion:\n",
    "        {}\n",
    "\n",
    "        Respond in the following format:\n",
    "        Observe: Your answer\n",
    "        \"\"\"\n",
    "    )\n",
    "    return state\n",
    "\n",
    "\n",
    "async def feedback_agent(state: SupervisorState) -> SupervisorState:\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=300,\n",
    "        model=LITE_MODEL,\n",
    "        api_key=LITE_LLM_API_KEY,\n",
    "        base_url=LITE_LLM_URL,\n",
    "        streaming=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    msgs = convert_agent_msg_to_llm_message(state[\"messages\"])\n",
    "    print(f\"\\n\\nFEEDBACK AGENT PROMPT\\n {msgs}\")\n",
    "    print(f\"\\n\\nFEEDBACK AGENT PROMPT\\n {state['chat_messages'][-1]}\")\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [SystemMessage(FEEDBACK_TEMPLATE)] + msgs\n",
    "    )\n",
    "    prompt = await prompt_template.ainvoke(input={})\n",
    "    feedback_response = await model.ainvoke(prompt)\n",
    "\n",
    "    interrupt_val = {\n",
    "        \"answer_to_revisit\": \"Please provide additional feedback\",\n",
    "    }\n",
    "    print(f\"\\n\\nFEEDBACK AGENT\\n {interrupt_val}\")\n",
    "    print(f\"\\n\\nFEEDBACK RESPONSE\\n {feedback_response}\")\n",
    "    value = interrupt(\n",
    "        interrupt_val,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"discrepancy\": state[\"discrepancy\"],\n",
    "        \"guidance\": state[\"guidance\"],\n",
    "        \"next_steps\": state[\"next_steps\"],\n",
    "        \"messages\": [interrupt_val],\n",
    "        \"chat_messages\": [feedback_response],\n",
    "    }\n",
    "\n",
    "\n",
    "async def guidance_agent(state: SupervisorState) -> SupervisorState:\n",
    "    print(\"\\n\\n\\nENTERING GUIDANCE\\n\\n\\n\")\n",
    "    tools = [search]\n",
    "    template = ChatPromptTemplate.from_template(GUIDANCE_TEMPLATE)\n",
    "    prompt = await template.ainvoke(\n",
    "        input={\n",
    "            \"tools\": render_text_description(tools),\n",
    "            \"context\": state[\"chat_messages\"][0][\"message\"],\n",
    "            \"answer\": state[\"chat_messages\"][-1][\"message\"],\n",
    "        }\n",
    "    )\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=300,\n",
    "        model=LITE_MODEL,\n",
    "        api_key=LITE_LLM_API_KEY,\n",
    "        base_url=LITE_LLM_URL,\n",
    "        streaming=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(f\"\\n\\nGUIDANCE AGENT PROMPT\\n {prompt}\")\n",
    "    agent = create_react_agent(model=model, tools=tools)\n",
    "    agent_response = await agent.ainvoke(prompt)\n",
    "    print(f\"\\n\\nGUIDANCE AGENT RESPONSE\\n {agent_response}\")\n",
    "    msg = AgentMessage(\n",
    "        message=agent_response[\"messages\"][-1],\n",
    "        role=\"guidance\",\n",
    "    )\n",
    "    return {\n",
    "        \"discrepancy\": state[\"discrepancy\"],\n",
    "        \"guidance\": state[\"guidance\"],\n",
    "        \"next_steps\": state[\"next_steps\"],\n",
    "        \"messages\": [msg],\n",
    "        \"chat_messages\": state[\"chat_messages\"],\n",
    "    }\n",
    "\n",
    "\n",
    "async def finish(state: SupervisorState) -> SupervisorState:\n",
    "    return state\n",
    "\n",
    "\n",
    "async def next_step(\n",
    "    state: SupervisorState,\n",
    ") -> Literal[\"guidance\", \"feedback\", \"discrepancy\", \"finish\", \"grading\"]:\n",
    "    if len(state[\"next_steps\"]) > 0:\n",
    "        if state[\"next_steps\"][-1] == \"guidance\":\n",
    "            return \"guidance\"\n",
    "        elif state[\"next_steps\"][-1] == \"discrepancy\":\n",
    "            return \"discrepancy\"\n",
    "        elif state[\"next_steps\"][-1] == \"feedback\":\n",
    "            return \"feedback\"\n",
    "        elif state[\"next_steps\"][-1] == \"grading\":\n",
    "            return \"grading\"\n",
    "    return \"finish\""
   ],
   "id": "75d188fb23c8ab52",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T11:31:22.486139Z",
     "start_time": "2025-07-07T11:31:22.476900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GuidanceHelperStdOutput(BaseModel):\n",
    "    has_user_answered: bool = Field(\n",
    "        description=\"Whether the user has correctly answered the topic at hand\"\n",
    "    )\n",
    "    expertise_level: str = Field(\n",
    "        description=\"The expertise user has self evaluated himself with\"\n",
    "    )\n",
    "    expertise_id: int = Field(description=\"The expertise or grade ID\")\n",
    "    is_more_categories_answered: bool = Field(\n",
    "        description=\"if multiple categories have been selected\", default=False\n",
    "    )\n",
    "    should_admin_be_involved: bool = Field(\n",
    "        description=\"Whether the admin should be involved if user is evading the topic or fooling around\"\n",
    "    )\n",
    "    message: str = Field(description=\"Message to send to the user\")\n",
    "\n",
    "\n",
    "async def get_grades_or_expertise() -> List[Grade]:\n",
    "    \"\"\"\n",
    "    Useful tool to retrieve current grades or expertise level grading system\n",
    "    :return: List of json representing those grades and all their fields\n",
    "    \"\"\"\n",
    "    async for session in get_session():\n",
    "        service: BaseService[Grade, int, Any, Any] = BaseService(Grade, session)\n",
    "        all_db_grades = await service.list_all()\n",
    "        all_grades_json: List[str] = []\n",
    "        for grade in all_db_grades:\n",
    "            json_grade = grade.model_dump_json()\n",
    "            all_grades_json.append(json_grade)\n",
    "        return all_grades_json\n",
    "\n",
    "\n",
    "async def get_current_grade_for_user(\n",
    "    skill_id: int, user_id: int\n",
    ") -> None | Row[Any] | RowMapping | Any:\n",
    "    \"\"\"\n",
    "    Useful tool to expertise level or grade for specific skill for a user\n",
    "    :param skill_id: id of the skill user is looking (ex. Java Development, DevOPS etc...)\n",
    "    :param user_id: id of the user\n",
    "    :return: UserSkill explaining the expertise level for specific user and skill\n",
    "    \"\"\"\n",
    "    async for session in get_session():\n",
    "        service: BaseService[UserSkills, int, Any, Any] = BaseService(\n",
    "            UserSkills, session\n",
    "        )\n",
    "        filters = {\n",
    "            \"skill_id\": skill_id,\n",
    "            \"user_id\": user_id,\n",
    "        }\n",
    "        proper_skill = await service.list_all(filters=filters)\n",
    "        if len(proper_skill) == 0:\n",
    "            return None\n",
    "        return proper_skill[0]\n",
    "\n",
    "\n",
    "async def is_valid_response_for_guidance(\n",
    "    chunk: BaseMessage,\n",
    ") -> Tuple[bool, Optional[AIMessage]]:\n",
    "    if \"agent\" in chunk and \"messages\" in chunk[\"agent\"]:\n",
    "        msg_content = chunk[\"agent\"][\"messages\"][-1]\n",
    "        if isinstance(msg_content, AIMessage) and msg_content.content != \"\":\n",
    "            return True, msg_content\n",
    "    return False, None\n",
    "\n",
    "\n",
    "async def strip_unnecessary_chars(llm_str: AIMessage) -> str:\n",
    "    content = llm_str.content\n",
    "    content = content.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "    return content\n",
    "\n",
    "\n",
    "async def provide_guidance(\n",
    "    msgs: List[str],\n",
    "    user: User,\n",
    "    skill: Skill,\n",
    ") -> AsyncGenerator[GuidanceHelperStdOutput, Any]:\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model=LITE_MODEL,\n",
    "        api_key=LITE_LLM_API_KEY,\n",
    "        base_url=LITE_LLM_URL,\n",
    "        streaming=True,\n",
    "        verbose=True,\n",
    "        callbacks=[custom_callback],\n",
    "    )\n",
    "    tools = [\n",
    "        StructuredTool.from_function(\n",
    "            function=get_grades_or_expertise,\n",
    "            coroutine=get_grades_or_expertise,\n",
    "        ),\n",
    "        StructuredTool.from_function(\n",
    "            function=get_current_grade_for_user,\n",
    "            coroutine=get_current_grade_for_user,\n",
    "        ),\n",
    "    ]\n",
    "    intermediate_steps = []\n",
    "\n",
    "    system_msg = GUIDANCE_PROMPT\n",
    "    agent = create_react_agent(model=model, tools=tools)\n",
    "    async for chunk in agent.astream(\n",
    "        {\n",
    "            \"messages\": [SystemMessage(system_msg)] + msgs,\n",
    "            \"tools\": render_text_description(tools),\n",
    "            \"context\": msgs[0],\n",
    "            \"intermediate_steps\": intermediate_steps,\n",
    "            \"user\": user,\n",
    "            \"skill\": skill,\n",
    "        }\n",
    "    ):\n",
    "        print(\"PROVIDE FEEDBACK\", chunk)\n",
    "        (is_valid, msg_content) = is_valid_response_for_guidance(chunk)\n",
    "        if is_valid:\n",
    "            content = strip_unnecessary_chars(msg_content)\n",
    "            try:\n",
    "                ch = GuidanceHelperStdOutput.model_validate_json(content)\n",
    "                yield ch\n",
    "            except ValidationError:\n",
    "                yield GuidanceHelperStdOutput(\n",
    "                    has_user_answered=False,\n",
    "                    expertise_level=\"\",\n",
    "                    expertise_id=0,\n",
    "                    should_admin_be_involved=False,\n",
    "                    message=content,\n",
    "                )"
   ],
   "id": "7a10fb444068f50b",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T11:51:30.618033Z",
     "start_time": "2025-07-07T11:51:27.480747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state_graph = StateGraph(SupervisorState)\n",
    "\n",
    "state_graph.add_node(\"supervisor\", supervisor_agent)\n",
    "state_graph.add_node(\"discrepancy\", discrepancy_agent)\n",
    "state_graph.add_node(\"guidance\", guidance_agent)\n",
    "state_graph.add_node(\"feedback\", feedback_agent)\n",
    "state_graph.add_node(\"grading\", grading_agent)\n",
    "state_graph.add_node(\"finish\", finish)\n",
    "state_graph.add_edge(START, \"supervisor\")\n",
    "state_graph.add_conditional_edges(\"supervisor\", next_step)\n",
    "state_graph.add_edge(\"discrepancy\", \"supervisor\")\n",
    "state_graph.add_edge(\"guidance\", \"supervisor\")\n",
    "state_graph.add_edge(\"grading\", \"supervisor\")\n",
    "state_graph.add_edge(\"feedback\", \"supervisor\")\n",
    "state_graph.add_edge(\"finish\", END)\n",
    "\n",
    "graph = state_graph.compile()\n",
    "\n",
    "\n",
    "state_vals = SupervisorState(\n",
    "    discrepancy=DiscrepancyValues(skill_id=1, user_id=1, grade_id=7),\n",
    "    guidance=GuidanceValue(messages=[]),\n",
    "    next_steps=[],\n",
    "    messages=[],\n",
    "    chat_messages=[\n",
    "        {\n",
    "            \"message\": \"\"\"\n",
    "                Expertise Levels in Backup and Recovery\n",
    "                Welcome! In this discussion, we will explore the various expertise levels related to the skill of Backup and Recovery. Understanding these levels will help you select the appropriate expertise that aligns with your current knowledge and experience.\n",
    "\n",
    "                Here are the available expertise grades:\n",
    "\n",
    "                Not Informed: You have no prior knowledge of the topic.\n",
    "                Informed Basics: You understand the basic concepts of Backup and Recovery.\n",
    "                Informed in Details: You have a deeper understanding of the strategies involved.\n",
    "                Practice and Lab Examples: You can apply your knowledge through practical examples and lab work.\n",
    "                Production Maintenance: You are capable of maintaining backup systems in a production environment.\n",
    "                Production from Scratch: You can set up backup systems from the ground up.\n",
    "                Educator/Expert: You possess extensive knowledge and can teach others about Backup and Recovery.\n",
    "                Consider your current level of understanding and experience to choose the expertise that best fits you. This will enhance your learning and engagement in our discussion!\n",
    "                \"\"\",\n",
    "            \"role\": \"ai\",\n",
    "        },\n",
    "        {\n",
    "            \"message\": \"\"\"\n",
    "                Hmmm what are you referring when talking about backup and recovery\n",
    "                \"\"\",\n",
    "            \"role\": \"human\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "async for chunk in graph.astream(state_vals):\n",
    "    print(chunk)"
   ],
   "id": "f56d3d97754f5747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SUPERVISOR AGENT PROMPT\n",
      " messages=[HumanMessage(content=\"\\n        You are supervising multiple agents doing their job. You distribute the tasks to them to solve the problem stated in the discussion (Question and Answer).\\n        When the user has clearly identified itself with specific grade or expertise level provide a Finish Answer!\\n        The identification or clarification of expertise level must be only for one grade, the user must not be between two or more grades or expertise level.\\n        It has to be precisely one expertise level!\\n        While this identification is not yet clear, always ask user for additional feedback!\\n        Utilize grading and experience levels provided in the first question, do not utilize any other under no circumstances!\\n        Stay on the topic of the discussion, warn the user if the topic is diverging!\\n        Always validate and check discrepancies about users experience/grade level when you find out which grade is it!\\n        You have the following agents at your disposal:\\n        discrepancy -> agent that finds the discrepancies between submitted expertise and the one saved within the database\\n        guidance -> agent that helps the user and answers his questions when he asks questions. Does not provide guidance on further learning and additional clarification, only answers the questions that user asked\\n        feedback -> agent that asks user for further clarifications and or additional input.\\n        grading -> agent that takes the current conversations and establishes the users final grade or let's you know if additional research is needed\\n        Take note of evasion of topic from user, and please notify the user that the admin and managers can be involved if it happens 4 or 5 times!\\n    \\n        Do not use bold or any other text styling!\\n        Before final answer always check with grading and discrepancy agent is everything ok!\\n    \\n        Break the problem with steps and do exactly the following:\\n        Thought: Write your thoughts here\\n        Call: which agent to call (discrepancy, feedback or guidance), state only the agent name without additional information\\n        Observe: Observe agents response\\n        Think/Agent/Observe can happen as many times as needed at most 10 times.\\n        Final Answer: You know the answer and finished the execution\\n    \\n        Begin!\\n    \\n        Question: \\n                Expertise Levels in Backup and Recovery\\n                Welcome! In this discussion, we will explore the various expertise levels related to the skill of Backup and Recovery. Understanding these levels will help you select the appropriate expertise that aligns with your current knowledge and experience.\\n\\n                Here are the available expertise grades:\\n\\n                Not Informed: You have no prior knowledge of the topic.\\n                Informed Basics: You understand the basic concepts of Backup and Recovery.\\n                Informed in Details: You have a deeper understanding of the strategies involved.\\n                Practice and Lab Examples: You can apply your knowledge through practical examples and lab work.\\n                Production Maintenance: You are capable of maintaining backup systems in a production environment.\\n                Production from Scratch: You can set up backup systems from the ground up.\\n                Educator/Expert: You possess extensive knowledge and can teach others about Backup and Recovery.\\n                Consider your current level of understanding and experience to choose the expertise that best fits you. This will enhance your learning and engagement in our discussion!\\n                \\nAnswer: \\n                Hmmm what are you referring when talking about backup and recovery\\n                \\n        \\n        \", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "\n",
      "SUPERVISOR AGENT RESPONSE\n",
      " content='Thought: The user seems to be unclear about the topic of backup and recovery, which may indicate a lack of knowledge or a need for clarification. I need to gather more information about their understanding before proceeding.\\n\\nCall: feedback\\n' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b'} id='run--f51b1ef8-c83e-40d3-80d1-e4d1d12a6cec-0'\n",
      "\n",
      "\n",
      "\n",
      "IS MATCHING THIS\n",
      "\n",
      "\n",
      "\n",
      "{'supervisor': {'discrepancy': DiscrepancyValues(grade_id=7, skill_id=1, user_id=1), 'guidance': GuidanceValue(messages=[]), 'next_steps': ['feedback'], 'messages': [AgentMessage(message=AIMessage(content='Thought: The user seems to be unclear about the topic of backup and recovery, which may indicate a lack of knowledge or a need for clarification. I need to gather more information about their understanding before proceeding.\\n\\nCall: feedback\\n', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b'}, id='run--f51b1ef8-c83e-40d3-80d1-e4d1d12a6cec-0'), role='supervisor')], 'chat_messages': [{'message': '\\n                Expertise Levels in Backup and Recovery\\n                Welcome! In this discussion, we will explore the various expertise levels related to the skill of Backup and Recovery. Understanding these levels will help you select the appropriate expertise that aligns with your current knowledge and experience.\\n\\n                Here are the available expertise grades:\\n\\n                Not Informed: You have no prior knowledge of the topic.\\n                Informed Basics: You understand the basic concepts of Backup and Recovery.\\n                Informed in Details: You have a deeper understanding of the strategies involved.\\n                Practice and Lab Examples: You can apply your knowledge through practical examples and lab work.\\n                Production Maintenance: You are capable of maintaining backup systems in a production environment.\\n                Production from Scratch: You can set up backup systems from the ground up.\\n                Educator/Expert: You possess extensive knowledge and can teach others about Backup and Recovery.\\n                Consider your current level of understanding and experience to choose the expertise that best fits you. This will enhance your learning and engagement in our discussion!\\n                ', 'role': 'ai'}, {'message': '\\n                Hmmm what are you referring when talking about backup and recovery\\n                ', 'role': 'human'}]}}\n",
      "\n",
      "\n",
      "FEEDBACK AGENT PROMPT\n",
      " [AIMessage(content='Thought: The user seems to be unclear about the topic of backup and recovery, which may indicate a lack of knowledge or a need for clarification. I need to gather more information about their understanding before proceeding.\\n\\nCall: feedback\\n', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b'}, id='run--f51b1ef8-c83e-40d3-80d1-e4d1d12a6cec-0')]\n",
      "\n",
      "\n",
      "FEEDBACK AGENT PROMPT\n",
      " {'message': '\\n                Hmmm what are you referring when talking about backup and recovery\\n                ', 'role': 'human'}\n",
      "\n",
      "\n",
      "FEEDBACK AGENT\n",
      " {'answer_to_revisit': 'Please provide additional feedback'}\n",
      "\n",
      "\n",
      "FEEDBACK RESPONSE\n",
      " content='It seems you may have questions or need clarification regarding backup and recovery processes. Backup refers to the practice of creating copies of data to protect it from loss, while recovery is the process of restoring that data when needed. \\n\\nIf you have specific aspects of backup and recovery youâ€™d like to discuss, such as methods, tools, or best practices, please let me know, and I can provide more detailed information tailored to your needs.' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b'} id='run--8e5159bc-56e7-489a-875a-21e7d2cd78d3-0'\n",
      "{'__interrupt__': (Interrupt(value={'answer_to_revisit': 'Please provide additional feedback'}, resumable=True, ns=['feedback:615caf4e-928f-e8c8-3ff9-02536f09eb9f']),)}\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T12:09:50.660447Z",
     "start_time": "2025-07-06T12:09:50.658638Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f5075fe3ec64844e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response = await guidance_agent(state_vals)\n",
    "print(response)"
   ],
   "id": "e6eabdc60c7d67db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(Image(graph.get_graph().draw_mermaid_png()))",
   "id": "7ba55fac9fbdbc64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7c3e9dea4521c81a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9acdb0b62d9f523",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
